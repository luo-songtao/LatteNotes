---
layout: post
tags: [hadoop,大数据,安装配置]
category: ['待整理']
---

#### 环境准备

1. 软件版本示例

    系统：CentOS7.5为例、2C4G

    三台服务器分配的IP地址：192.168.19.137/138/139

    规划：137作为hadoop-master，其他两台作为数据节点138、139分别为hadoop-slave1、hadoop-slave2

    jdk使用1.8版本

    hadoop使用2.9.1版本，下载地址：http://apache.claz.org/hadoop/common/hadoop-2.9.1/hadoop-2.9.1.tar.gz

2. host配置和主机名配置

    修改所有服务器的`/etc/hosts`文件，添加以下配置
    ```
    192.168.19.137 hadoop-master
    192.168.19.138 hadoop-slave1
    192.168.19.139 hadoop-slave2
    ```
    依次修改所有的服务器的主机名：HOSTNAME，以hadoop-master为例：在137服务器上

    `vi /etc/susconfig/network`
    ```
    HOSTNAME=hadoop-master
    ```

    执行`reboot now`后生效，注意需要一次修改每一台服务，改为对应的hadoop-slave1、hadoop-slave2等

    之后的配置将使用HOSTNAME进行域名配置，这样便于管理和识别

3. JDK安装：
    方法一：官网下载JDK，https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
    方法二：使用安装JDK：`yum -y install java-1.8.0-openjdk*

    安装后，配置环境变量，这里以方法一为例：

    下载JDK1.8.0解压放到`/root/bigdata`目录下，并设置软连接`/root/bigdata/jdk`指向它
    `vi /root/.bash_profile`
    ```
    export JAVE_HOME=/root/bigdata/jdk
    export PATH=$PATH:$JAVA_HOME/bin
    ```

    使用`source /root/.bash_profile`是配置立即生效

#### 免密登录

1. 以下以hadoop-master为例，配置服务器的本机无密码登录：

    生成密钥：`ssh-keygen -t rsa`

    追加公钥：`cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys`

    设置权限：`chmod 600 ~/.ssh/authorized_keys`

    验证本机能否无密码登录：`ssh hadoop-master`

    其余机器同样的步骤设置

2. 以下设置hadoop-master无密码登录hadoop-slave1、hadoop-slave2

    在hadoop-slave1上：
    - 先复制hadoop-master上的公钥到hadoop-slave1的`/root`目录下：
    `scp root@hadoop-master:/root/.ssh/id_rsa.pub /root/`

    - 然后将hadoop-master的公钥追加到hadoop-slave1的authorized_keys中：
    ```
    cat /root/id_rsa.pub >> ~/.ssh/authorized_keys
    rm -rf /root/id_rsa.pub
    ```

    在hadoop-master测试无密码登录hadoop-slave1：`ssh hadoop-slave1`

    hadoop-slave2同理依次配置

3. 与2相反，hadoop-slave1、hadoop-slave2也需要设置无密码登录hadoop-master，设置方法同理

#### hadoop-master的安装与配置

配置hadoop-master的hadoop环境
1. hadoop-master上下载并解压hadoop安装包放到指定目录，如`/root/bigdata/`，并未其设置软连接`/root/bigdata/hadoop`

    ```
    wget http://apache.claz.org/hadoop/common/hadoop-2.9.1/hadoop-2.9.1.tar.gz
    tar -xvf hadoop-2.9.1.tar.gz
    mv hadoop-2.9.1 /root/bigdata/
    ln -s /root/bigdata/hadoop-2.9.1 /root/bigdata/hadoop
    ```

2. 配置hadoop-master的hadoop环境变量：

    编辑`vi /root/.bash_profile`

    ```
    export HADOOP_HOME=/root/bigdata/hadoop
    export PATH=$PATH:$HADOOP_HOME/bin
    ```

    使用`source /root/.bash_profile`使之生效

**注意：进入`/root/bigdata/hadoop/etc/hadoop`目录**

3. 配置core-site.xml，修改hadoop的核心配置文件

    `hadoop.tmp.dir`：指定hadoop数据存储的临时文件夹；

    `fs.default.name`：指定NameNonde的IP地址和端口号
    ```
    <configuration>
        <property>
            <name>hadoop.tmp.dir</name>
            <value>/root/bigdata/hadoop/tmp</value>
        </property>
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://hadoop-master:9000</value>
        </property>
    </configuration>
    ```
    **注意：如没有配置`hadoop.tmp.dir`参数，此时系统默认的临时目录为：`/tmp`。而这个目录在每次重启后都会可能被删除，届时必须重新执行format才行，否则会出错**

    因此这里指定为hadoop home目录下的tmp路径。为避免带来其他问题，建议手动创建并赋予权限`mkdir /root/bigdata/hadoop/tmp && chmod 777 /root/bigdata/hadoop/tmp`

4. 配置hdfs-site.xml，修改HDFS的核心配置文件

    `dfs.replication`：指定HDFS的备份因子

    `dfs.name.dir`：指定namenode节点的文件存储目录

    `dfs.data.dir`：指定datanode节点的文件存储目录

    ```
     <configuration>
        <property>
            <name>dfs.replication</name>
            <value>3</value>
        </property>
        <property>
            <name>dfs.name.dir</name>
            <value>/root/bigdata/hadoop/hdfs/name</value>
        </property>
        <property>
            <name>dfs.data.dir</name>
            <value>/root/bigdata/hadoop/hdfs/data</value>
        </property>
    </configuration>
    ```

5. 配置mapred-site.xml，修改MapReduce的核心配置文件

    先拷贝mapred-site.xml.template为mapred-site.xml，再进行修改

    `mapreduce.framework.name`：设定yarn为MapReduce的资源管理器

    `mapred.job.tracker`：配置HTTP地址与端口

    ```
    <configuration>
      <property>
          <name>mapreduce.framework.name</name>
          <value>yarn</value>
      </property>
       <property>
          <name>mapred.job.tracker</name>
          <value>http://hadoop-master:9001</value>
      </property>
    </configuration>
    ```
6. 配置yarn-site.xml

    ```
    <configuration>
    <!-- Site specific YARN configuration properties -->
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
        </property>
        <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>hadoop-master</value>
        </property>

    </configuration>
    ```

7. 配置masters文件

   编辑`vi /root/bigdata/hadoop/etc/hadoop/masters`，如果没有则新建，该文件指定namenode节点所在的服务器

   ```
   hadoop-master
   ```

8. 配置slaves文件：(该文件只在Master机器上配置)

    编辑`vi /root/bigdata/hadoop/etc/hadoop/slaves`，该文件指定哪些服务器节点是datanode节点。删除locahost，添加所有datanode节点的主机名，即slave节点
    ```
    hadoop-slave1
    hadoop-slave2
    ```
#### hadoop-slave的安装与配置

hadoop slave服务器的配置与master的配置全部同步，以master为主，因此配置方法如下：

1. 拷贝master服务器上的hadoop目录到slave机器上，如在master服务器上：
    ```
    scp -r /root/bigdata/hadoop hadoop-slave1:/root/bigdata/
    scp -r /root/bigdata/hadoop hadoop-slave2:/root/bigdata/
    # 有多个则一一拷贝
    ```

2. 分别将slave机器上的hadoop配置文件夹(`hadoop/etc/hadoop`)里的slaves文件删除，该文件是master服务器独有的

3. 在slave机器上配置hadoop的环境变量`vi /root/.bash_profile`：
```
export HADOOP_HOME=/root/bigdata
export PATH=$PATH:$HADOOP_HOME/bin
```

`source /root/.bash_profile`

#### 启动Hadoop集群

完成以上配置则可以开始启动Hadoop集群

但在启动前还需要设置防火墙，测试阶段可以直接关闭所有机器的防火墙`service firewalld stop`，生成环境那么就需要设置端口过滤规则，这里不赘述

1. 初始化HDFS文件系统：

    在master服务器上：`hadoop namenode -format`

    该命令只需要在第一次启动服务前执行，之后不用再执行

2. 启动Hadoop：

    在master服务器上：`/root/bigdata/hadoop/sbin/start-all.sh`

3. 运行成功后，分别在master和slave服务器上使用`jps`查看hadoop的运行进程：

    master应有类似如下的几个进程：
    ```
    4673 SecondaryNameNode
    4475 NameNode
    4831 ResourceManager
    ```

    每个slave应有类似如下的几个进程：
    ```
    2405 DataNode
    2521 NodeManager
    ```

同时也可以通过master服务器的50070端口查看hadoop的WEB界面
