<!DOCTYPE html>













<html lang="en"
  
>

  <!--
  The Head
-->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Allow having a localized datetime different from the appearance language -->
  

  

    

    

  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.2.1" />
<meta property="og:title" content="Gaussian Distribution (1)" />
<meta name="author" content="luo-songtao" />
<meta property="og:locale" content="en" />
<meta name="description" content="Gaussian Distribution Univariate [\begin{aligned} \mathcal{N}(x\vert \mu, \sigma^2) = \frac {1}{\sqrt{2\pi \sigma^2}} \exp\left(- \frac {1}{2\sigma^2} (x-\mu)^2 \right) \end{aligned}] The integral of Gaussian distribution \[\begin{aligned} \int_{-\infty}^{+\infty} \mathcal{N}(x\vert \mu, \sigma^2) dx &amp;= \frac {1}{(2\pi \sigma^2)^{1/2}} \int_{-\infty}^{+\infty} \exp\left( -\frac {1}{2\sigma^2} (x-\mu)^2\right)dx \\ &amp;= \frac {1}{(2\pi \sigma^2)^{1/2}} \int_{-\infty}^{+\infty} \exp\left(-\left(\frac {x-\mu}{(2\sigma^2)^{1/2}}\right)^2\right)dx\qquad y=\frac {x-\mu}{(2\sigma^2)^{1/2}} \\ &amp;= \frac {1}{(2\pi \sigma^2)^{1/2}} \int_{-\infty}^{+\infty} \exp\left(-y^2\right) (2\sigma^2)^{1/2}dy \qquad \frac {dx}{dy} = (2\sigma^2)^{1/2} \\ &amp;= \frac {1}{\sqrt{\pi}}\int_{-\infty}^{+\infty} \exp\left(-y^2\right)dy \\ &amp;= 1 \end{aligned}\] we have uesed the property $\int_{-\infty}^{+\infty} \exp(-x^2)dx =\sqrt{\pi} $, the proof is given by: Firstly, if we let $I =\int_{-\infty}^{+\infty} \exp(-x^2)dx $, then we have $\int_{-\infty}^{+\infty} \exp(-x^2-y^2)dxdy = I^2$, and \[\begin{aligned} \mathrm{Let} \space I^2 &amp;= \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} \exp(-x^2-y^2)dxdy \qquad x=r\cos \theta, y=r\sin \theta \\ &amp;= \int_{0}^{+\infty}\int_{0}^{2\pi} \exp(-r^2)\left\vert\frac {\partial(x,y)}{\partial(r,\theta)} \right\vert d\theta dr \\&amp;= \int_{0}^{+\infty}\int_{0}^{2\pi} \exp(-r^2)\left\vert\begin{matrix} \cos\theta &amp; -r\sin\theta \\\sin\theta &amp; r\cos\theta \end{matrix} \right\vert d\theta dr \\ &amp;= \int_{0}^{+\infty}\int_{0}^{2\pi} \exp(-r^2)r d\theta dr \\&amp;= 2\pi \int_{0}^{+\infty} \exp(-r^2)r dr \\ &amp;= 2\pi \left.(-\frac {1}{2}\exp(-r^2) \right\vert_{0}^{\infty} \\ &amp;= 2\pi (0-(-\frac 12)) \\&amp;= \pi \end{aligned}\] Then we have: $I = \sqrt{\pi}$ The Mean \[\begin{aligned} \mathbb{E}[x] &amp;= \int_{-\infty}^{+\infty} x\mathcal{N}(x\vert \mu, \sigma^2) dx \\ &amp;= \frac {1}{(2\pi \sigma^2)^{1/2}}\int_{-\infty}^{+\infty} x \exp\left( -\frac {1}{2\sigma^2} (x-\mu)^2 \right) dx \\&amp;= \frac {1}{(2\pi \sigma^2)^{1/2}}\int_{-\infty}^{+\infty} \exp\left( -\frac {1}{2\sigma^2} y^2 \right)(y+\mu) dy \\&amp;= \frac {1}{(2\pi \sigma^2)^{1/2}} \left(0 + \mu\int_{-\infty}^{+\infty} \exp\left( -\frac {1}{2\sigma^2} y^2 \right) dy \right) \\&amp;= \mu \end{aligned}\] This is given by $f(y) = \exp\left( -\frac {1}{2\sigma^2} y^2 \right)y$ is an odd function on interval $(-\infty, \infty)$, and $\int_{-\infty}^{+\infty} \exp\left( -\frac {1}{2\sigma^2} y^2 \right) dy = \sqrt{2\pi \sigma^2}$ The Variance \[\begin{aligned} \qquad&amp; \frac {\partial \left(\int \mathcal{N}(x\vert \mu, \sigma^2) dx\right)} {\partial \sigma^2} = \frac {\partial 1}{\partial \sigma^2} \\ \Longrightarrow \qquad&amp; \int (-\frac 1{2\sigma^2} + \frac {(x-\mu)^2}{2\sigma^4}) \mathcal{N}(x\vert \mu, \sigma^2) dx = 0 \\ \Longrightarrow \qquad&amp; \int (x-\mu)^2 \mathcal{N}(x\vert \mu, \sigma^2) dx = \sigma^2 \\ \Longrightarrow \qquad&amp; \mathrm{var}[x] = \int (x-\mathbb{E}[x])^2 \mathcal{N}(x\vert \mu, \sigma^2) dx = \sigma^2 \end{aligned}\] Multivariate [\begin{aligned} \mathcal{N}(\boldsymbol{x}\vert \boldsymbol{\mu}, \Sigma) = \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \exp\left(-\frac 12 (\boldsymbol{x} - \boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \right) \end{aligned}] Mahalanobis Distance \[\begin{aligned} D_{x,y} = \sqrt{(x-y)^TS^{-1}(x-y)} \end{aligned}\] The Gaussian distribution will be constant on surfaces in $x$-space for which this quadratic form is constant. \[\begin{aligned} \Delta^2 = (\boldsymbol{x} - \boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \end{aligned}\] The Covariance Matrix $\Sigma$ Firstly, the matrix $\Sigma$ can be taken to be symmetric, without loss of generality, because any antisymmetric component would disappear from the exponent. Suppose an arbitrary percision matrix $\Lambda$ can be written as $\Lambda^S + \Lambda^A$, where they statify: \[\begin{aligned} \Lambda^S = \frac {\Lambda_{ij}+\Lambda_{ji}}{2}, \qquad \Lambda^A = \frac {\Lambda_{ij}-\Lambda_{ji}}{2} \end{aligned}\] Then $\Lambda^S = (\Lambda^S)^T$, $\Lambda^A = -(\Lambda^A)^T$ So in the quadratic form, the value of $(\boldsymbol{x} - \boldsymbol{\mu})^T\Lambda^A(\boldsymbol{x} - \boldsymbol{\mu})$ is zero, and then only the symmetric matrix $\Lambda^S$ left. Then because $\Sigma$ is rela, symmetric matrix, its eigenvalues will be real, and its eigenvectors can be chosen to form an orthonormal set, so that: \[\begin{aligned} \boldsymbol{u}_i^T\boldsymbol{u}_j = \left\{\begin{aligned}1\qquad &amp;i=j \\ 0 \qquad &amp;i\neq j \end{aligned} \right. \end{aligned}\] And then, we have: \[\begin{aligned} \Sigma &amp;= \sum_{i=1}^D \lambda_i \boldsymbol{u}_i\boldsymbol{u}_i^T \\ \Sigma^{-1} &amp;= \sum_{i=1}^D \frac 1 \lambda_i \boldsymbol{u}_i\boldsymbol{u}_i^T \\ \vert \Sigma \vert &amp;= \prod_{i=1}^D \lambda_i \end{aligned}\] Substituting this reuslt into the quadratic form, we obtain: \[\begin{aligned} \Delta^2 &amp;= (\boldsymbol{x} - \boldsymbol{\mu})^T \left(\sum_{i=1}^D \frac 1 \lambda_i \boldsymbol{u}_i\boldsymbol{u}_j^T \right)(\boldsymbol{x} - \boldsymbol{\mu}) \\&amp;= \sum_{i=1}^D \frac {y_i^2} {\lambda_i} \qquad let \space y_i = \boldsymbol{u}^T(\boldsymbol{x} - \boldsymbol{\mu}) \end{aligned}\] Interpreting ${y_i}$ as a new corrdinate system defined by the otthonormal vectors $\boldsymbol{u}_i$ that are shifted and rotated with respect to the original $x_i$ coordinates. Forming the vector $\boldsymbol{y}=(y_1,y_2,\cdots,y_D)^T$, we have \[\boldsymbol{y} = U(\boldsymbol{x} - \boldsymbol{\mu})\] where the row of $U$ is $\boldsymbol{u}_i^T$, moreover $U$ is an orthogonal matrix, $UU^T = U^TU=I$ For the Gaussian distribution to be well defined, it is necessary for all of the eigenvalues $\lambda_i$ of the covariance matrix to be strictly positive, oterwise the distribution cannot be properly normalized. In going from $\boldsymbol{x}$ to the $\boldsymbol{y}$ corrdinate system, we have a Jacobian matrix $\boldsymbol{J}$, and : \[\begin{aligned} \frac {\partial y_i}{\partial x_j} = mu_ij = U_{ij} = J_{ij} \end{aligned}\] Then we can see $\boldsymbol{J} = U$, and $\vert J \vert = \vert U \vert = 1$ \[\begin{aligned} p(\boldsymbol{y}) = p(\boldsymbol{x})\vert J \vert &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\prod_{i=1}^D \lambda_i^{1/2}} \exp(-\frac 12 \sum_{i=1}^D\frac {y_i^2}{\lambda_i}) \\&amp;= \prod_{i=1}^D \frac 1{(2\pi\lambda_i)^{1/2}} \exp(-\frac {y_i^2}{2\lambda_i}) \end{aligned}\] this is the product of $D$ independent univariate Gaussian distribution. The Moments of Gaussian distribution First Order Moments \[\begin{aligned} \mathbb{E}[\boldsymbol{x}] &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 (\boldsymbol{x} - \boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \right)\boldsymbol{x} d\boldsymbol{x} \\ &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)(\boldsymbol{z}+\boldsymbol{\mu}) d\boldsymbol{z} \end{aligned}\] and because $f(\boldsymbol{z}) = \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)\boldsymbol{z}$ is an odd function, then the integrals over the range $(-\infty, \infty)$ will be zero. Thus: \[\begin{aligned} \mathbb{E}[\boldsymbol{x}] = \boldsymbol{\mu} \end{aligned}\] Second Order Moments \[\begin{aligned} \mathbb{E}[\boldsymbol{x}\boldsymbol{x}^T] &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 (\boldsymbol{x} - \boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \right)\boldsymbol{x}\boldsymbol{x}^T d\boldsymbol{x} \\ &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)(\boldsymbol{z}+\boldsymbol{\mu})(\boldsymbol{z}+\boldsymbol{\mu})^T d\boldsymbol{z} \\ &amp;= \boldsymbol{\mu}\boldsymbol{\mu}^T + \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)\boldsymbol{z}\boldsymbol{z}^T d\boldsymbol{z} \end{aligned}\] and because $\boldsymbol{z} = (\boldsymbol{x}-\boldsymbol{\mu}) = U\boldsymbol{y} = \sum_{j=1}^D y_j \boldsymbol{u}_j$. Thus: \[\begin{aligned} \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)\boldsymbol{z}\boldsymbol{z}^T d\boldsymbol{z} &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \sum_{j=1}^D y_j \boldsymbol{u}_j^T \left( \sum_{i=1}^D\frac {1}{\lambda_i}\boldsymbol{u}_i\boldsymbol{u}_i^T \right)\sum_{k=1}^D y_k \boldsymbol{u}_k \right)\sum_{m=1}^D y_m \boldsymbol{u}_m \sum_{n=1}^D y_n \boldsymbol{u}_n^T d\boldsymbol{y} \\ &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T\int \exp\left(-\frac 12 \left( \sum_{i=1}^D\frac {y_i}{\lambda_i} \boldsymbol{u}_i^T \right)\sum_{k=1}^D y_k \boldsymbol{u}_k \right) y_m y_n d\boldsymbol{y} \\&amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T\int \exp\left(-\frac 12 \sum_{i=1}^D\frac {y_i^2}{\lambda_i} \right) y_m y_n d\boldsymbol{y} \\ &amp;= \sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T \prod_{i=1}^D \int \frac {1}{(2\pi \lambda_i)^{1/2}}\exp(-\frac {y_i^2}{2\lambda_i})y_my_n d\boldsymbol{y}\end{aligned}\] The integrals $\forall i\neq m$, and $i\neq n$ will be 1,so: \[\begin{aligned} &amp; \left\{\begin{aligned} &amp;\sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T \int \frac {1}{(2\pi \lambda_m)^{1/2}}\exp(-\frac {y_m^2}{2\lambda_m})y_m dy_m y_ndy_n \qquad m\neq n, i = m \\ &amp;\sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T \int \frac {1}{(2\pi \lambda_n)^{1/2}}\exp(-\frac {y_n^2}{2\lambda_n})y_ndy_n y_m dy_m \qquad m\neq n, i=n \\ &amp;\sum_{i=1}^D \boldsymbol{u}_i\boldsymbol{u}_i^T \int \frac {1}{(2\pi \lambda_i)^{1/2}}\exp(-\frac {y_i^2}{2\lambda_i})y_i^2 dy_i \qquad i=m=n \end{aligned}\right. \\ =&amp; \left\{\begin{aligned} &amp;0 \qquad m\neq n, i = m \\ &amp;0 \qquad m\neq n, i = n \\ &amp;\sum_{i=1}^D \boldsymbol{u}_i\boldsymbol{u}_i^T (0+\lambda_i) \qquad i=m=n \end{aligned}\right. \end{aligned}\] The final step, we have use the $\mathbb{E}[x^2] = \mu^2 + \sigma^2$, thus: \[\begin{aligned} \mathbb{E}[\boldsymbol{x}\boldsymbol{x}^T] &amp;= \boldsymbol{\mu}\boldsymbol{\mu}^T + 0 + 0 + \sum_{i=1}^D \boldsymbol{u}_i\boldsymbol{u}_i^T \lambda_i \\ &amp;= \boldsymbol{\mu}\boldsymbol{\mu}^T+ \Sigma\end{aligned}\] And then : \[\begin{aligned} \mathrm{cov}[\boldsymbol{x}] = \mathbb{E}[\boldsymbol{x}\boldsymbol{x}^T] - \mathbb{E}[\boldsymbol{x}]\mathbb{E}[\boldsymbol{x}]^T = \Sigma \end{aligned}\] The number of free parameters in the Gaussian distribution: A general symmetric covariance matrix $\Sigma$ will have $\frac {D^2-D}{2} + D = \frac {D(D+1)}{2}$ independent parameters, and there another $D$ independent parameters in $\boldsymbol{\mu}$, then giving $\frac {D(D+3)}{2}$ parameters in total. Thus we can see, it is grows quadratically with $D$ If the covariance matrix $\Sigma$ is diagonal, then the number of parameters will be $2D$ in total. Especially, if we consider the covariance matrix $\Sigma$ with $\Sigma = \sigma^2 I$, isotropic covariance, then the number of parameters will be $D+1$ in total." />
<meta property="og:description" content="Gaussian Distribution Univariate [\begin{aligned} \mathcal{N}(x\vert \mu, \sigma^2) = \frac {1}{\sqrt{2\pi \sigma^2}} \exp\left(- \frac {1}{2\sigma^2} (x-\mu)^2 \right) \end{aligned}] The integral of Gaussian distribution \[\begin{aligned} \int_{-\infty}^{+\infty} \mathcal{N}(x\vert \mu, \sigma^2) dx &amp;= \frac {1}{(2\pi \sigma^2)^{1/2}} \int_{-\infty}^{+\infty} \exp\left( -\frac {1}{2\sigma^2} (x-\mu)^2\right)dx \\ &amp;= \frac {1}{(2\pi \sigma^2)^{1/2}} \int_{-\infty}^{+\infty} \exp\left(-\left(\frac {x-\mu}{(2\sigma^2)^{1/2}}\right)^2\right)dx\qquad y=\frac {x-\mu}{(2\sigma^2)^{1/2}} \\ &amp;= \frac {1}{(2\pi \sigma^2)^{1/2}} \int_{-\infty}^{+\infty} \exp\left(-y^2\right) (2\sigma^2)^{1/2}dy \qquad \frac {dx}{dy} = (2\sigma^2)^{1/2} \\ &amp;= \frac {1}{\sqrt{\pi}}\int_{-\infty}^{+\infty} \exp\left(-y^2\right)dy \\ &amp;= 1 \end{aligned}\] we have uesed the property $\int_{-\infty}^{+\infty} \exp(-x^2)dx =\sqrt{\pi} $, the proof is given by: Firstly, if we let $I =\int_{-\infty}^{+\infty} \exp(-x^2)dx $, then we have $\int_{-\infty}^{+\infty} \exp(-x^2-y^2)dxdy = I^2$, and \[\begin{aligned} \mathrm{Let} \space I^2 &amp;= \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} \exp(-x^2-y^2)dxdy \qquad x=r\cos \theta, y=r\sin \theta \\ &amp;= \int_{0}^{+\infty}\int_{0}^{2\pi} \exp(-r^2)\left\vert\frac {\partial(x,y)}{\partial(r,\theta)} \right\vert d\theta dr \\&amp;= \int_{0}^{+\infty}\int_{0}^{2\pi} \exp(-r^2)\left\vert\begin{matrix} \cos\theta &amp; -r\sin\theta \\\sin\theta &amp; r\cos\theta \end{matrix} \right\vert d\theta dr \\ &amp;= \int_{0}^{+\infty}\int_{0}^{2\pi} \exp(-r^2)r d\theta dr \\&amp;= 2\pi \int_{0}^{+\infty} \exp(-r^2)r dr \\ &amp;= 2\pi \left.(-\frac {1}{2}\exp(-r^2) \right\vert_{0}^{\infty} \\ &amp;= 2\pi (0-(-\frac 12)) \\&amp;= \pi \end{aligned}\] Then we have: $I = \sqrt{\pi}$ The Mean \[\begin{aligned} \mathbb{E}[x] &amp;= \int_{-\infty}^{+\infty} x\mathcal{N}(x\vert \mu, \sigma^2) dx \\ &amp;= \frac {1}{(2\pi \sigma^2)^{1/2}}\int_{-\infty}^{+\infty} x \exp\left( -\frac {1}{2\sigma^2} (x-\mu)^2 \right) dx \\&amp;= \frac {1}{(2\pi \sigma^2)^{1/2}}\int_{-\infty}^{+\infty} \exp\left( -\frac {1}{2\sigma^2} y^2 \right)(y+\mu) dy \\&amp;= \frac {1}{(2\pi \sigma^2)^{1/2}} \left(0 + \mu\int_{-\infty}^{+\infty} \exp\left( -\frac {1}{2\sigma^2} y^2 \right) dy \right) \\&amp;= \mu \end{aligned}\] This is given by $f(y) = \exp\left( -\frac {1}{2\sigma^2} y^2 \right)y$ is an odd function on interval $(-\infty, \infty)$, and $\int_{-\infty}^{+\infty} \exp\left( -\frac {1}{2\sigma^2} y^2 \right) dy = \sqrt{2\pi \sigma^2}$ The Variance \[\begin{aligned} \qquad&amp; \frac {\partial \left(\int \mathcal{N}(x\vert \mu, \sigma^2) dx\right)} {\partial \sigma^2} = \frac {\partial 1}{\partial \sigma^2} \\ \Longrightarrow \qquad&amp; \int (-\frac 1{2\sigma^2} + \frac {(x-\mu)^2}{2\sigma^4}) \mathcal{N}(x\vert \mu, \sigma^2) dx = 0 \\ \Longrightarrow \qquad&amp; \int (x-\mu)^2 \mathcal{N}(x\vert \mu, \sigma^2) dx = \sigma^2 \\ \Longrightarrow \qquad&amp; \mathrm{var}[x] = \int (x-\mathbb{E}[x])^2 \mathcal{N}(x\vert \mu, \sigma^2) dx = \sigma^2 \end{aligned}\] Multivariate [\begin{aligned} \mathcal{N}(\boldsymbol{x}\vert \boldsymbol{\mu}, \Sigma) = \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \exp\left(-\frac 12 (\boldsymbol{x} - \boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \right) \end{aligned}] Mahalanobis Distance \[\begin{aligned} D_{x,y} = \sqrt{(x-y)^TS^{-1}(x-y)} \end{aligned}\] The Gaussian distribution will be constant on surfaces in $x$-space for which this quadratic form is constant. \[\begin{aligned} \Delta^2 = (\boldsymbol{x} - \boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \end{aligned}\] The Covariance Matrix $\Sigma$ Firstly, the matrix $\Sigma$ can be taken to be symmetric, without loss of generality, because any antisymmetric component would disappear from the exponent. Suppose an arbitrary percision matrix $\Lambda$ can be written as $\Lambda^S + \Lambda^A$, where they statify: \[\begin{aligned} \Lambda^S = \frac {\Lambda_{ij}+\Lambda_{ji}}{2}, \qquad \Lambda^A = \frac {\Lambda_{ij}-\Lambda_{ji}}{2} \end{aligned}\] Then $\Lambda^S = (\Lambda^S)^T$, $\Lambda^A = -(\Lambda^A)^T$ So in the quadratic form, the value of $(\boldsymbol{x} - \boldsymbol{\mu})^T\Lambda^A(\boldsymbol{x} - \boldsymbol{\mu})$ is zero, and then only the symmetric matrix $\Lambda^S$ left. Then because $\Sigma$ is rela, symmetric matrix, its eigenvalues will be real, and its eigenvectors can be chosen to form an orthonormal set, so that: \[\begin{aligned} \boldsymbol{u}_i^T\boldsymbol{u}_j = \left\{\begin{aligned}1\qquad &amp;i=j \\ 0 \qquad &amp;i\neq j \end{aligned} \right. \end{aligned}\] And then, we have: \[\begin{aligned} \Sigma &amp;= \sum_{i=1}^D \lambda_i \boldsymbol{u}_i\boldsymbol{u}_i^T \\ \Sigma^{-1} &amp;= \sum_{i=1}^D \frac 1 \lambda_i \boldsymbol{u}_i\boldsymbol{u}_i^T \\ \vert \Sigma \vert &amp;= \prod_{i=1}^D \lambda_i \end{aligned}\] Substituting this reuslt into the quadratic form, we obtain: \[\begin{aligned} \Delta^2 &amp;= (\boldsymbol{x} - \boldsymbol{\mu})^T \left(\sum_{i=1}^D \frac 1 \lambda_i \boldsymbol{u}_i\boldsymbol{u}_j^T \right)(\boldsymbol{x} - \boldsymbol{\mu}) \\&amp;= \sum_{i=1}^D \frac {y_i^2} {\lambda_i} \qquad let \space y_i = \boldsymbol{u}^T(\boldsymbol{x} - \boldsymbol{\mu}) \end{aligned}\] Interpreting ${y_i}$ as a new corrdinate system defined by the otthonormal vectors $\boldsymbol{u}_i$ that are shifted and rotated with respect to the original $x_i$ coordinates. Forming the vector $\boldsymbol{y}=(y_1,y_2,\cdots,y_D)^T$, we have \[\boldsymbol{y} = U(\boldsymbol{x} - \boldsymbol{\mu})\] where the row of $U$ is $\boldsymbol{u}_i^T$, moreover $U$ is an orthogonal matrix, $UU^T = U^TU=I$ For the Gaussian distribution to be well defined, it is necessary for all of the eigenvalues $\lambda_i$ of the covariance matrix to be strictly positive, oterwise the distribution cannot be properly normalized. In going from $\boldsymbol{x}$ to the $\boldsymbol{y}$ corrdinate system, we have a Jacobian matrix $\boldsymbol{J}$, and : \[\begin{aligned} \frac {\partial y_i}{\partial x_j} = mu_ij = U_{ij} = J_{ij} \end{aligned}\] Then we can see $\boldsymbol{J} = U$, and $\vert J \vert = \vert U \vert = 1$ \[\begin{aligned} p(\boldsymbol{y}) = p(\boldsymbol{x})\vert J \vert &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\prod_{i=1}^D \lambda_i^{1/2}} \exp(-\frac 12 \sum_{i=1}^D\frac {y_i^2}{\lambda_i}) \\&amp;= \prod_{i=1}^D \frac 1{(2\pi\lambda_i)^{1/2}} \exp(-\frac {y_i^2}{2\lambda_i}) \end{aligned}\] this is the product of $D$ independent univariate Gaussian distribution. The Moments of Gaussian distribution First Order Moments \[\begin{aligned} \mathbb{E}[\boldsymbol{x}] &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 (\boldsymbol{x} - \boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \right)\boldsymbol{x} d\boldsymbol{x} \\ &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)(\boldsymbol{z}+\boldsymbol{\mu}) d\boldsymbol{z} \end{aligned}\] and because $f(\boldsymbol{z}) = \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)\boldsymbol{z}$ is an odd function, then the integrals over the range $(-\infty, \infty)$ will be zero. Thus: \[\begin{aligned} \mathbb{E}[\boldsymbol{x}] = \boldsymbol{\mu} \end{aligned}\] Second Order Moments \[\begin{aligned} \mathbb{E}[\boldsymbol{x}\boldsymbol{x}^T] &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 (\boldsymbol{x} - \boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \right)\boldsymbol{x}\boldsymbol{x}^T d\boldsymbol{x} \\ &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)(\boldsymbol{z}+\boldsymbol{\mu})(\boldsymbol{z}+\boldsymbol{\mu})^T d\boldsymbol{z} \\ &amp;= \boldsymbol{\mu}\boldsymbol{\mu}^T + \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)\boldsymbol{z}\boldsymbol{z}^T d\boldsymbol{z} \end{aligned}\] and because $\boldsymbol{z} = (\boldsymbol{x}-\boldsymbol{\mu}) = U\boldsymbol{y} = \sum_{j=1}^D y_j \boldsymbol{u}_j$. Thus: \[\begin{aligned} \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)\boldsymbol{z}\boldsymbol{z}^T d\boldsymbol{z} &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \sum_{j=1}^D y_j \boldsymbol{u}_j^T \left( \sum_{i=1}^D\frac {1}{\lambda_i}\boldsymbol{u}_i\boldsymbol{u}_i^T \right)\sum_{k=1}^D y_k \boldsymbol{u}_k \right)\sum_{m=1}^D y_m \boldsymbol{u}_m \sum_{n=1}^D y_n \boldsymbol{u}_n^T d\boldsymbol{y} \\ &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T\int \exp\left(-\frac 12 \left( \sum_{i=1}^D\frac {y_i}{\lambda_i} \boldsymbol{u}_i^T \right)\sum_{k=1}^D y_k \boldsymbol{u}_k \right) y_m y_n d\boldsymbol{y} \\&amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T\int \exp\left(-\frac 12 \sum_{i=1}^D\frac {y_i^2}{\lambda_i} \right) y_m y_n d\boldsymbol{y} \\ &amp;= \sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T \prod_{i=1}^D \int \frac {1}{(2\pi \lambda_i)^{1/2}}\exp(-\frac {y_i^2}{2\lambda_i})y_my_n d\boldsymbol{y}\end{aligned}\] The integrals $\forall i\neq m$, and $i\neq n$ will be 1,so: \[\begin{aligned} &amp; \left\{\begin{aligned} &amp;\sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T \int \frac {1}{(2\pi \lambda_m)^{1/2}}\exp(-\frac {y_m^2}{2\lambda_m})y_m dy_m y_ndy_n \qquad m\neq n, i = m \\ &amp;\sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T \int \frac {1}{(2\pi \lambda_n)^{1/2}}\exp(-\frac {y_n^2}{2\lambda_n})y_ndy_n y_m dy_m \qquad m\neq n, i=n \\ &amp;\sum_{i=1}^D \boldsymbol{u}_i\boldsymbol{u}_i^T \int \frac {1}{(2\pi \lambda_i)^{1/2}}\exp(-\frac {y_i^2}{2\lambda_i})y_i^2 dy_i \qquad i=m=n \end{aligned}\right. \\ =&amp; \left\{\begin{aligned} &amp;0 \qquad m\neq n, i = m \\ &amp;0 \qquad m\neq n, i = n \\ &amp;\sum_{i=1}^D \boldsymbol{u}_i\boldsymbol{u}_i^T (0+\lambda_i) \qquad i=m=n \end{aligned}\right. \end{aligned}\] The final step, we have use the $\mathbb{E}[x^2] = \mu^2 + \sigma^2$, thus: \[\begin{aligned} \mathbb{E}[\boldsymbol{x}\boldsymbol{x}^T] &amp;= \boldsymbol{\mu}\boldsymbol{\mu}^T + 0 + 0 + \sum_{i=1}^D \boldsymbol{u}_i\boldsymbol{u}_i^T \lambda_i \\ &amp;= \boldsymbol{\mu}\boldsymbol{\mu}^T+ \Sigma\end{aligned}\] And then : \[\begin{aligned} \mathrm{cov}[\boldsymbol{x}] = \mathbb{E}[\boldsymbol{x}\boldsymbol{x}^T] - \mathbb{E}[\boldsymbol{x}]\mathbb{E}[\boldsymbol{x}]^T = \Sigma \end{aligned}\] The number of free parameters in the Gaussian distribution: A general symmetric covariance matrix $\Sigma$ will have $\frac {D^2-D}{2} + D = \frac {D(D+1)}{2}$ independent parameters, and there another $D$ independent parameters in $\boldsymbol{\mu}$, then giving $\frac {D(D+3)}{2}$ parameters in total. Thus we can see, it is grows quadratically with $D$ If the covariance matrix $\Sigma$ is diagonal, then the number of parameters will be $2D$ in total. Especially, if we consider the covariance matrix $\Sigma$ with $\Sigma = \sigma^2 I$, isotropic covariance, then the number of parameters will be $D+1$ in total." />
<link rel="canonical" href="http://0.0.0.0:4000/posts/gaussian_distribution_1/" />
<meta property="og:url" content="http://0.0.0.0:4000/posts/gaussian_distribution_1/" />
<meta property="og:site_name" content="Candy Note" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-02-20T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Gaussian Distribution (1)" />
<meta name="twitter:site" content="@twitter_username" />
<meta name="twitter:creator" content="@luo-songtao" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"luo-songtao"},"dateModified":"2021-02-20T00:00:00+00:00","datePublished":"2021-02-20T00:00:00+00:00","description":"Gaussian Distribution Univariate [\\begin{aligned} \\mathcal{N}(x\\vert \\mu, \\sigma^2) = \\frac {1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(- \\frac {1}{2\\sigma^2} (x-\\mu)^2 \\right) \\end{aligned}] The integral of Gaussian distribution \\[\\begin{aligned} \\int_{-\\infty}^{+\\infty} \\mathcal{N}(x\\vert \\mu, \\sigma^2) dx &amp;= \\frac {1}{(2\\pi \\sigma^2)^{1/2}} \\int_{-\\infty}^{+\\infty} \\exp\\left( -\\frac {1}{2\\sigma^2} (x-\\mu)^2\\right)dx \\\\ &amp;= \\frac {1}{(2\\pi \\sigma^2)^{1/2}} \\int_{-\\infty}^{+\\infty} \\exp\\left(-\\left(\\frac {x-\\mu}{(2\\sigma^2)^{1/2}}\\right)^2\\right)dx\\qquad y=\\frac {x-\\mu}{(2\\sigma^2)^{1/2}} \\\\ &amp;= \\frac {1}{(2\\pi \\sigma^2)^{1/2}} \\int_{-\\infty}^{+\\infty} \\exp\\left(-y^2\\right) (2\\sigma^2)^{1/2}dy \\qquad \\frac {dx}{dy} = (2\\sigma^2)^{1/2} \\\\ &amp;= \\frac {1}{\\sqrt{\\pi}}\\int_{-\\infty}^{+\\infty} \\exp\\left(-y^2\\right)dy \\\\ &amp;= 1 \\end{aligned}\\] we have uesed the property $\\int_{-\\infty}^{+\\infty} \\exp(-x^2)dx =\\sqrt{\\pi} $, the proof is given by: Firstly, if we let $I =\\int_{-\\infty}^{+\\infty} \\exp(-x^2)dx $, then we have $\\int_{-\\infty}^{+\\infty} \\exp(-x^2-y^2)dxdy = I^2$, and \\[\\begin{aligned} \\mathrm{Let} \\space I^2 &amp;= \\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty} \\exp(-x^2-y^2)dxdy \\qquad x=r\\cos \\theta, y=r\\sin \\theta \\\\ &amp;= \\int_{0}^{+\\infty}\\int_{0}^{2\\pi} \\exp(-r^2)\\left\\vert\\frac {\\partial(x,y)}{\\partial(r,\\theta)} \\right\\vert d\\theta dr \\\\&amp;= \\int_{0}^{+\\infty}\\int_{0}^{2\\pi} \\exp(-r^2)\\left\\vert\\begin{matrix} \\cos\\theta &amp; -r\\sin\\theta \\\\\\sin\\theta &amp; r\\cos\\theta \\end{matrix} \\right\\vert d\\theta dr \\\\ &amp;= \\int_{0}^{+\\infty}\\int_{0}^{2\\pi} \\exp(-r^2)r d\\theta dr \\\\&amp;= 2\\pi \\int_{0}^{+\\infty} \\exp(-r^2)r dr \\\\ &amp;= 2\\pi \\left.(-\\frac {1}{2}\\exp(-r^2) \\right\\vert_{0}^{\\infty} \\\\ &amp;= 2\\pi (0-(-\\frac 12)) \\\\&amp;= \\pi \\end{aligned}\\] Then we have: $I = \\sqrt{\\pi}$ The Mean \\[\\begin{aligned} \\mathbb{E}[x] &amp;= \\int_{-\\infty}^{+\\infty} x\\mathcal{N}(x\\vert \\mu, \\sigma^2) dx \\\\ &amp;= \\frac {1}{(2\\pi \\sigma^2)^{1/2}}\\int_{-\\infty}^{+\\infty} x \\exp\\left( -\\frac {1}{2\\sigma^2} (x-\\mu)^2 \\right) dx \\\\&amp;= \\frac {1}{(2\\pi \\sigma^2)^{1/2}}\\int_{-\\infty}^{+\\infty} \\exp\\left( -\\frac {1}{2\\sigma^2} y^2 \\right)(y+\\mu) dy \\\\&amp;= \\frac {1}{(2\\pi \\sigma^2)^{1/2}} \\left(0 + \\mu\\int_{-\\infty}^{+\\infty} \\exp\\left( -\\frac {1}{2\\sigma^2} y^2 \\right) dy \\right) \\\\&amp;= \\mu \\end{aligned}\\] This is given by $f(y) = \\exp\\left( -\\frac {1}{2\\sigma^2} y^2 \\right)y$ is an odd function on interval $(-\\infty, \\infty)$, and $\\int_{-\\infty}^{+\\infty} \\exp\\left( -\\frac {1}{2\\sigma^2} y^2 \\right) dy = \\sqrt{2\\pi \\sigma^2}$ The Variance \\[\\begin{aligned} \\qquad&amp; \\frac {\\partial \\left(\\int \\mathcal{N}(x\\vert \\mu, \\sigma^2) dx\\right)} {\\partial \\sigma^2} = \\frac {\\partial 1}{\\partial \\sigma^2} \\\\ \\Longrightarrow \\qquad&amp; \\int (-\\frac 1{2\\sigma^2} + \\frac {(x-\\mu)^2}{2\\sigma^4}) \\mathcal{N}(x\\vert \\mu, \\sigma^2) dx = 0 \\\\ \\Longrightarrow \\qquad&amp; \\int (x-\\mu)^2 \\mathcal{N}(x\\vert \\mu, \\sigma^2) dx = \\sigma^2 \\\\ \\Longrightarrow \\qquad&amp; \\mathrm{var}[x] = \\int (x-\\mathbb{E}[x])^2 \\mathcal{N}(x\\vert \\mu, \\sigma^2) dx = \\sigma^2 \\end{aligned}\\] Multivariate [\\begin{aligned} \\mathcal{N}(\\boldsymbol{x}\\vert \\boldsymbol{\\mu}, \\Sigma) = \\frac {1}{(2\\pi)^{D/2}} \\frac {1}{\\vert\\Sigma\\vert^{1/2}} \\exp\\left(-\\frac 12 (\\boldsymbol{x} - \\boldsymbol{\\mu})^T\\Sigma^{-1}(\\boldsymbol{x} - \\boldsymbol{\\mu}) \\right) \\end{aligned}] Mahalanobis Distance \\[\\begin{aligned} D_{x,y} = \\sqrt{(x-y)^TS^{-1}(x-y)} \\end{aligned}\\] The Gaussian distribution will be constant on surfaces in $x$-space for which this quadratic form is constant. \\[\\begin{aligned} \\Delta^2 = (\\boldsymbol{x} - \\boldsymbol{\\mu})^T\\Sigma^{-1}(\\boldsymbol{x} - \\boldsymbol{\\mu}) \\end{aligned}\\] The Covariance Matrix $\\Sigma$ Firstly, the matrix $\\Sigma$ can be taken to be symmetric, without loss of generality, because any antisymmetric component would disappear from the exponent. Suppose an arbitrary percision matrix $\\Lambda$ can be written as $\\Lambda^S + \\Lambda^A$, where they statify: \\[\\begin{aligned} \\Lambda^S = \\frac {\\Lambda_{ij}+\\Lambda_{ji}}{2}, \\qquad \\Lambda^A = \\frac {\\Lambda_{ij}-\\Lambda_{ji}}{2} \\end{aligned}\\] Then $\\Lambda^S = (\\Lambda^S)^T$, $\\Lambda^A = -(\\Lambda^A)^T$ So in the quadratic form, the value of $(\\boldsymbol{x} - \\boldsymbol{\\mu})^T\\Lambda^A(\\boldsymbol{x} - \\boldsymbol{\\mu})$ is zero, and then only the symmetric matrix $\\Lambda^S$ left. Then because $\\Sigma$ is rela, symmetric matrix, its eigenvalues will be real, and its eigenvectors can be chosen to form an orthonormal set, so that: \\[\\begin{aligned} \\boldsymbol{u}_i^T\\boldsymbol{u}_j = \\left\\{\\begin{aligned}1\\qquad &amp;i=j \\\\ 0 \\qquad &amp;i\\neq j \\end{aligned} \\right. \\end{aligned}\\] And then, we have: \\[\\begin{aligned} \\Sigma &amp;= \\sum_{i=1}^D \\lambda_i \\boldsymbol{u}_i\\boldsymbol{u}_i^T \\\\ \\Sigma^{-1} &amp;= \\sum_{i=1}^D \\frac 1 \\lambda_i \\boldsymbol{u}_i\\boldsymbol{u}_i^T \\\\ \\vert \\Sigma \\vert &amp;= \\prod_{i=1}^D \\lambda_i \\end{aligned}\\] Substituting this reuslt into the quadratic form, we obtain: \\[\\begin{aligned} \\Delta^2 &amp;= (\\boldsymbol{x} - \\boldsymbol{\\mu})^T \\left(\\sum_{i=1}^D \\frac 1 \\lambda_i \\boldsymbol{u}_i\\boldsymbol{u}_j^T \\right)(\\boldsymbol{x} - \\boldsymbol{\\mu}) \\\\&amp;= \\sum_{i=1}^D \\frac {y_i^2} {\\lambda_i} \\qquad let \\space y_i = \\boldsymbol{u}^T(\\boldsymbol{x} - \\boldsymbol{\\mu}) \\end{aligned}\\] Interpreting ${y_i}$ as a new corrdinate system defined by the otthonormal vectors $\\boldsymbol{u}_i$ that are shifted and rotated with respect to the original $x_i$ coordinates. Forming the vector $\\boldsymbol{y}=(y_1,y_2,\\cdots,y_D)^T$, we have \\[\\boldsymbol{y} = U(\\boldsymbol{x} - \\boldsymbol{\\mu})\\] where the row of $U$ is $\\boldsymbol{u}_i^T$, moreover $U$ is an orthogonal matrix, $UU^T = U^TU=I$ For the Gaussian distribution to be well defined, it is necessary for all of the eigenvalues $\\lambda_i$ of the covariance matrix to be strictly positive, oterwise the distribution cannot be properly normalized. In going from $\\boldsymbol{x}$ to the $\\boldsymbol{y}$ corrdinate system, we have a Jacobian matrix $\\boldsymbol{J}$, and : \\[\\begin{aligned} \\frac {\\partial y_i}{\\partial x_j} = mu_ij = U_{ij} = J_{ij} \\end{aligned}\\] Then we can see $\\boldsymbol{J} = U$, and $\\vert J \\vert = \\vert U \\vert = 1$ \\[\\begin{aligned} p(\\boldsymbol{y}) = p(\\boldsymbol{x})\\vert J \\vert &amp;= \\frac {1}{(2\\pi)^{D/2}} \\frac {1}{\\prod_{i=1}^D \\lambda_i^{1/2}} \\exp(-\\frac 12 \\sum_{i=1}^D\\frac {y_i^2}{\\lambda_i}) \\\\&amp;= \\prod_{i=1}^D \\frac 1{(2\\pi\\lambda_i)^{1/2}} \\exp(-\\frac {y_i^2}{2\\lambda_i}) \\end{aligned}\\] this is the product of $D$ independent univariate Gaussian distribution. The Moments of Gaussian distribution First Order Moments \\[\\begin{aligned} \\mathbb{E}[\\boldsymbol{x}] &amp;= \\frac {1}{(2\\pi)^{D/2}} \\frac {1}{\\vert\\Sigma\\vert^{1/2}} \\int \\exp\\left(-\\frac 12 (\\boldsymbol{x} - \\boldsymbol{\\mu})^T\\Sigma^{-1}(\\boldsymbol{x} - \\boldsymbol{\\mu}) \\right)\\boldsymbol{x} d\\boldsymbol{x} \\\\ &amp;= \\frac {1}{(2\\pi)^{D/2}} \\frac {1}{\\vert\\Sigma\\vert^{1/2}} \\int \\exp\\left(-\\frac 12 \\boldsymbol{z}^T\\Sigma^{-1}\\boldsymbol{z} \\right)(\\boldsymbol{z}+\\boldsymbol{\\mu}) d\\boldsymbol{z} \\end{aligned}\\] and because $f(\\boldsymbol{z}) = \\exp\\left(-\\frac 12 \\boldsymbol{z}^T\\Sigma^{-1}\\boldsymbol{z} \\right)\\boldsymbol{z}$ is an odd function, then the integrals over the range $(-\\infty, \\infty)$ will be zero. Thus: \\[\\begin{aligned} \\mathbb{E}[\\boldsymbol{x}] = \\boldsymbol{\\mu} \\end{aligned}\\] Second Order Moments \\[\\begin{aligned} \\mathbb{E}[\\boldsymbol{x}\\boldsymbol{x}^T] &amp;= \\frac {1}{(2\\pi)^{D/2}} \\frac {1}{\\vert\\Sigma\\vert^{1/2}} \\int \\exp\\left(-\\frac 12 (\\boldsymbol{x} - \\boldsymbol{\\mu})^T\\Sigma^{-1}(\\boldsymbol{x} - \\boldsymbol{\\mu}) \\right)\\boldsymbol{x}\\boldsymbol{x}^T d\\boldsymbol{x} \\\\ &amp;= \\frac {1}{(2\\pi)^{D/2}} \\frac {1}{\\vert\\Sigma\\vert^{1/2}} \\int \\exp\\left(-\\frac 12 \\boldsymbol{z}^T\\Sigma^{-1}\\boldsymbol{z} \\right)(\\boldsymbol{z}+\\boldsymbol{\\mu})(\\boldsymbol{z}+\\boldsymbol{\\mu})^T d\\boldsymbol{z} \\\\ &amp;= \\boldsymbol{\\mu}\\boldsymbol{\\mu}^T + \\frac {1}{(2\\pi)^{D/2}} \\frac {1}{\\vert\\Sigma\\vert^{1/2}} \\int \\exp\\left(-\\frac 12 \\boldsymbol{z}^T\\Sigma^{-1}\\boldsymbol{z} \\right)\\boldsymbol{z}\\boldsymbol{z}^T d\\boldsymbol{z} \\end{aligned}\\] and because $\\boldsymbol{z} = (\\boldsymbol{x}-\\boldsymbol{\\mu}) = U\\boldsymbol{y} = \\sum_{j=1}^D y_j \\boldsymbol{u}_j$. Thus: \\[\\begin{aligned} \\frac {1}{(2\\pi)^{D/2}} \\frac {1}{\\vert\\Sigma\\vert^{1/2}} \\int \\exp\\left(-\\frac 12 \\boldsymbol{z}^T\\Sigma^{-1}\\boldsymbol{z} \\right)\\boldsymbol{z}\\boldsymbol{z}^T d\\boldsymbol{z} &amp;= \\frac {1}{(2\\pi)^{D/2}} \\frac {1}{\\vert\\Sigma\\vert^{1/2}} \\int \\exp\\left(-\\frac 12 \\sum_{j=1}^D y_j \\boldsymbol{u}_j^T \\left( \\sum_{i=1}^D\\frac {1}{\\lambda_i}\\boldsymbol{u}_i\\boldsymbol{u}_i^T \\right)\\sum_{k=1}^D y_k \\boldsymbol{u}_k \\right)\\sum_{m=1}^D y_m \\boldsymbol{u}_m \\sum_{n=1}^D y_n \\boldsymbol{u}_n^T d\\boldsymbol{y} \\\\ &amp;= \\frac {1}{(2\\pi)^{D/2}} \\frac {1}{\\vert\\Sigma\\vert^{1/2}} \\sum_{m=1}^D\\sum_{n=1}^D \\boldsymbol{u}_m\\boldsymbol{u}_n^T\\int \\exp\\left(-\\frac 12 \\left( \\sum_{i=1}^D\\frac {y_i}{\\lambda_i} \\boldsymbol{u}_i^T \\right)\\sum_{k=1}^D y_k \\boldsymbol{u}_k \\right) y_m y_n d\\boldsymbol{y} \\\\&amp;= \\frac {1}{(2\\pi)^{D/2}} \\frac {1}{\\vert\\Sigma\\vert^{1/2}} \\sum_{m=1}^D\\sum_{n=1}^D \\boldsymbol{u}_m\\boldsymbol{u}_n^T\\int \\exp\\left(-\\frac 12 \\sum_{i=1}^D\\frac {y_i^2}{\\lambda_i} \\right) y_m y_n d\\boldsymbol{y} \\\\ &amp;= \\sum_{m=1}^D\\sum_{n=1}^D \\boldsymbol{u}_m\\boldsymbol{u}_n^T \\prod_{i=1}^D \\int \\frac {1}{(2\\pi \\lambda_i)^{1/2}}\\exp(-\\frac {y_i^2}{2\\lambda_i})y_my_n d\\boldsymbol{y}\\end{aligned}\\] The integrals $\\forall i\\neq m$, and $i\\neq n$ will be 1,so: \\[\\begin{aligned} &amp; \\left\\{\\begin{aligned} &amp;\\sum_{m=1}^D\\sum_{n=1}^D \\boldsymbol{u}_m\\boldsymbol{u}_n^T \\int \\frac {1}{(2\\pi \\lambda_m)^{1/2}}\\exp(-\\frac {y_m^2}{2\\lambda_m})y_m dy_m y_ndy_n \\qquad m\\neq n, i = m \\\\ &amp;\\sum_{m=1}^D\\sum_{n=1}^D \\boldsymbol{u}_m\\boldsymbol{u}_n^T \\int \\frac {1}{(2\\pi \\lambda_n)^{1/2}}\\exp(-\\frac {y_n^2}{2\\lambda_n})y_ndy_n y_m dy_m \\qquad m\\neq n, i=n \\\\ &amp;\\sum_{i=1}^D \\boldsymbol{u}_i\\boldsymbol{u}_i^T \\int \\frac {1}{(2\\pi \\lambda_i)^{1/2}}\\exp(-\\frac {y_i^2}{2\\lambda_i})y_i^2 dy_i \\qquad i=m=n \\end{aligned}\\right. \\\\ =&amp; \\left\\{\\begin{aligned} &amp;0 \\qquad m\\neq n, i = m \\\\ &amp;0 \\qquad m\\neq n, i = n \\\\ &amp;\\sum_{i=1}^D \\boldsymbol{u}_i\\boldsymbol{u}_i^T (0+\\lambda_i) \\qquad i=m=n \\end{aligned}\\right. \\end{aligned}\\] The final step, we have use the $\\mathbb{E}[x^2] = \\mu^2 + \\sigma^2$, thus: \\[\\begin{aligned} \\mathbb{E}[\\boldsymbol{x}\\boldsymbol{x}^T] &amp;= \\boldsymbol{\\mu}\\boldsymbol{\\mu}^T + 0 + 0 + \\sum_{i=1}^D \\boldsymbol{u}_i\\boldsymbol{u}_i^T \\lambda_i \\\\ &amp;= \\boldsymbol{\\mu}\\boldsymbol{\\mu}^T+ \\Sigma\\end{aligned}\\] And then : \\[\\begin{aligned} \\mathrm{cov}[\\boldsymbol{x}] = \\mathbb{E}[\\boldsymbol{x}\\boldsymbol{x}^T] - \\mathbb{E}[\\boldsymbol{x}]\\mathbb{E}[\\boldsymbol{x}]^T = \\Sigma \\end{aligned}\\] The number of free parameters in the Gaussian distribution: A general symmetric covariance matrix $\\Sigma$ will have $\\frac {D^2-D}{2} + D = \\frac {D(D+1)}{2}$ independent parameters, and there another $D$ independent parameters in $\\boldsymbol{\\mu}$, then giving $\\frac {D(D+3)}{2}$ parameters in total. Thus we can see, it is grows quadratically with $D$ If the covariance matrix $\\Sigma$ is diagonal, then the number of parameters will be $2D$ in total. Especially, if we consider the covariance matrix $\\Sigma$ with $\\Sigma = \\sigma^2 I$, isotropic covariance, then the number of parameters will be $D+1$ in total.","headline":"Gaussian Distribution (1)","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/posts/gaussian_distribution_1/"},"url":"http://0.0.0.0:4000/posts/gaussian_distribution_1/"}</script>
<!-- End Jekyll SEO tag -->


  <title>Gaussian Distribution (1) | Candy Note
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Candy Note">
<meta name="application-name" content="Candy Note">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  

    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">

  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>

</head>


  
    <!--
  Switch the mode between dark and light.
-->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() { return "mode"; }
    static get MODE_ATTR() { return "data-mode"; }
    static get DARK_MODE() { return "dark"; }
    static get LIGHT_MODE() { return "light"; }
    static get ID() { return "mode-toggle"; }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener("change", () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }

          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();

      });

    } /* constructor() */

    get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); }

    get isSysDarkPrefer() { return this.sysDarkPrefers.matches; }

    get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; }

    get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; }

    get hasMode() { return this.mode != null; }

    get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode
        || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      $('html').removeAttr(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage({
        direction: ModeToggle.ID,
        message: this.modeStatus
      }, "*");
    }

  } /* ModeToggle */

  const toggle = new ModeToggle();

  function flipMode() {
    if (toggle.hasMode) {
      if (toggle.isSysDarkPrefer) {
        if (toggle.isLightMode) {
          toggle.clearMode();
        } else {
          toggle.setLight();
        }

      } else {
        if (toggle.isDarkMode) {
          toggle.clearMode();
        } else {
          toggle.setDark();
        }
      }

    } else {
      if (toggle.isSysDarkPrefer) {
        toggle.setLight();
      } else {
        toggle.setDark();
      }
    }

    toggle.notify();

  } /* flipMode() */

</script>

  

  <body data-spy="scroll" data-target="#toc" data-topbar-visible="true">

    <!--
  The Side Bar
-->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper text-center">
    <div id="avatar">
      <a href="/" alt="avatar" class="mx-auto">
        
          
          <img src="
            
              /assets/img/head.jpg
            
          " alt="avatar" onerror="this.style.display='none'">
        
      </a>
    </div>

    <div class="site-title mt-3">
      <a href="/">Candy Note</a>
    </div>
    <div class="site-subtitle font-italic">Personal Notes</div>

  </div><!-- .profile-wrapper -->

  <ul class="w-100">

    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i>
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    
    <li class="nav-item">
      <a href="/categories/" class="nav-link">
        <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>CATEGORIES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tags/" class="nav-link">
        <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>TAGS</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/archives/" class="nav-link">
        <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ARCHIVES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/about/" class="nav-link">
        <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ABOUT</span>
      </a>
    </li> <!-- .nav-item -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center">

    
      <button class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
      <a href="https://github.com/github_username" aria-label="github"
        target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
      

    
      

      
      <a href="https://twitter.com/twitter_username" aria-label="twitter"
        target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
      

    
      

      
      <a href="
          javascript:location.href = 'mailto:' + ['ryomawithlst','gmail.com'].join('@')" aria-label="email"
        >
        <i class="fas fa-envelope"></i>
      </a>
      

    
      

      
      <a href="/feed.xml" aria-label="rss"
        >
        <i class="fas fa-rss"></i>
      </a>
      

    

  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <!--
  The Top Bar
-->

<div id="topbar-wrapper" class="row justify-content-center">
  <div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between">
    <span id="breadcrumb">

    

    

      

        
          <span>
            <a href="/">
              Home
            </a>
          </span>

        

      

        

      

        

          
            <span>Gaussian Distribution (1)</span>
          

        

      

    

    </span><!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      Post
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input class="form-control" id="search-input" type="search"
        aria-label="search" autocomplete="off" placeholder="Search...">
    </span>
    <span id="search-cancel" >Cancel</span>
  </div>

</div>


    <div id="main-wrapper">
      <div id="main">

        









<div class="row">

  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-8">
    <div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">

    

    
      
      
        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Add attribute 'hide-bullet' to the checkbox list -->



<!-- images -->





<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  

  
  

  




<!-- Wrap prompt element of blockquote with the <div> tag -->







<!-- return -->







<h1 data-toc-skip>Gaussian Distribution (1)</h1>

<div class="post-meta text-muted">

  <!-- author -->
  <div>
    
    

    

    By
    <em>
      
        <a href="https://github.com/luo-songtao">luo-songtao</a>
      
    </em>
  </div>

  <div class="d-flex">
    <div>
      <!-- published date -->
      <span>
        Posted
        <!--
  Date format snippet
  See: ${JS_ROOT}/utils/timeago.js
-->

<em class="timeago"
    data-ts="1613779200"
    
      data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll"
    
    >
  2021-02-20
</em>

      </span>

      <!-- lastmod date -->
      

      <!-- read time -->
      <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->



<!-- words per minute  -->










<!-- return element -->
<span class="readtime" data-toggle="tooltip" data-placement="bottom"
  title="1123 words">
  <em>6 min</em> read</span>


      <!-- page views -->
      
    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <h2 id="gaussian-distribution"><span class="mr-2">Gaussian Distribution</span><a href="#gaussian-distribution" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2>

<h3 id="univariate"><span class="mr-2">Univariate</span><a href="#univariate" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3>

\[\begin{aligned} \mathcal{N}(x\vert \mu, \sigma^2) = \frac {1}{\sqrt{2\pi \sigma^2}} \exp\left(- \frac {1}{2\sigma^2} (x-\mu)^2 \right) \end{aligned}\]

<ul>
  <li>
    <p>The integral of Gaussian distribution</p>

\[\begin{aligned} \int_{-\infty}^{+\infty} \mathcal{N}(x\vert \mu, \sigma^2)  dx &amp;=  \frac {1}{(2\pi \sigma^2)^{1/2}}  \int_{-\infty}^{+\infty}  \exp\left( -\frac {1}{2\sigma^2} (x-\mu)^2\right)dx \\ &amp;= \frac {1}{(2\pi \sigma^2)^{1/2}}  \int_{-\infty}^{+\infty} \exp\left(-\left(\frac {x-\mu}{(2\sigma^2)^{1/2}}\right)^2\right)dx\qquad y=\frac {x-\mu}{(2\sigma^2)^{1/2}} \\ &amp;= \frac {1}{(2\pi \sigma^2)^{1/2}}  \int_{-\infty}^{+\infty} \exp\left(-y^2\right) (2\sigma^2)^{1/2}dy \qquad \frac {dx}{dy} = (2\sigma^2)^{1/2} \\ &amp;= \frac {1}{\sqrt{\pi}}\int_{-\infty}^{+\infty}  \exp\left(-y^2\right)dy \\ &amp;= 1 \end{aligned}\]

    <ul>
      <li>
        <p>we have uesed the property $\int_{-\infty}^{+\infty}  \exp(-x^2)dx =\sqrt{\pi} $, the proof is given by:</p>

        <ul>
          <li>
            <p>Firstly, if we let $I =\int_{-\infty}^{+\infty}  \exp(-x^2)dx $, then we have $\int_{-\infty}^{+\infty}  \exp(-x^2-y^2)dxdy = I^2$, and</p>

\[\begin{aligned} \mathrm{Let} \space I^2 &amp;= \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}  \exp(-x^2-y^2)dxdy \qquad x=r\cos \theta, y=r\sin \theta \\ &amp;=  \int_{0}^{+\infty}\int_{0}^{2\pi} \exp(-r^2)\left\vert\frac {\partial(x,y)}{\partial(r,\theta)} \right\vert d\theta dr \\&amp;=    \int_{0}^{+\infty}\int_{0}^{2\pi} \exp(-r^2)\left\vert\begin{matrix} \cos\theta &amp; -r\sin\theta  \\\sin\theta &amp; r\cos\theta  \end{matrix} \right\vert d\theta dr \\ &amp;=  \int_{0}^{+\infty}\int_{0}^{2\pi} \exp(-r^2)r d\theta dr \\&amp;=   2\pi \int_{0}^{+\infty} \exp(-r^2)r  dr \\ &amp;= 2\pi \left.(-\frac {1}{2}\exp(-r^2)  \right\vert_{0}^{\infty} \\ &amp;= 2\pi (0-(-\frac 12)) \\&amp;= \pi \end{aligned}\]
          </li>
          <li>
            <p>Then we have: $I = \sqrt{\pi}$</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>The Mean</p>

\[\begin{aligned} \mathbb{E}[x] &amp;= \int_{-\infty}^{+\infty} x\mathcal{N}(x\vert \mu, \sigma^2)  dx \\ &amp;=   \frac {1}{(2\pi \sigma^2)^{1/2}}\int_{-\infty}^{+\infty} x \exp\left( -\frac {1}{2\sigma^2} (x-\mu)^2 \right)  dx \\&amp;= \frac {1}{(2\pi \sigma^2)^{1/2}}\int_{-\infty}^{+\infty}  \exp\left( -\frac {1}{2\sigma^2} y^2 \right)(y+\mu) dy \\&amp;= \frac {1}{(2\pi \sigma^2)^{1/2}} \left(0 + \mu\int_{-\infty}^{+\infty}  \exp\left( -\frac {1}{2\sigma^2} y^2 \right) dy  \right)  \\&amp;= \mu \end{aligned}\]

    <ul>
      <li>This is given by $f(y) =  \exp\left( -\frac {1}{2\sigma^2} y^2 \right)y$ is an odd function on interval $(-\infty, \infty)$, and $\int_{-\infty}^{+\infty}  \exp\left( -\frac {1}{2\sigma^2} y^2 \right) dy = \sqrt{2\pi \sigma^2}$</li>
    </ul>
  </li>
  <li>
    <p>The Variance</p>

\[\begin{aligned} \qquad&amp; \frac {\partial \left(\int \mathcal{N}(x\vert \mu, \sigma^2) dx\right)} {\partial \sigma^2} = \frac {\partial 1}{\partial \sigma^2} \\ \Longrightarrow \qquad&amp; \int (-\frac 1{2\sigma^2} + \frac {(x-\mu)^2}{2\sigma^4}) \mathcal{N}(x\vert \mu, \sigma^2) dx = 0 \\ \Longrightarrow \qquad&amp; \int (x-\mu)^2 \mathcal{N}(x\vert \mu, \sigma^2) dx = \sigma^2 \\ \Longrightarrow \qquad&amp; \mathrm{var}[x] = \int (x-\mathbb{E}[x])^2  \mathcal{N}(x\vert \mu, \sigma^2) dx = \sigma^2  \end{aligned}\]
  </li>
</ul>

<h3 id="multivariate"><span class="mr-2">Multivariate</span><a href="#multivariate" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3>

\[\begin{aligned} \mathcal{N}(\boldsymbol{x}\vert \boldsymbol{\mu}, \Sigma) = \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \exp\left(-\frac 12 (\boldsymbol{x} - \boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \right) \end{aligned}\]

<ul>
  <li>
    <p><strong>Mahalanobis Distance</strong></p>

\[\begin{aligned} D_{x,y} = \sqrt{(x-y)^TS^{-1}(x-y)} \end{aligned}\]
  </li>
  <li>
    <p>The Gaussian distribution will be constant on surfaces in $x$-space for which this quadratic form is constant.</p>

\[\begin{aligned} \Delta^2 = (\boldsymbol{x} - \boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \end{aligned}\]
  </li>
  <li>
    <p>The <strong>Covariance Matrix</strong> $\Sigma$</p>

    <ul>
      <li>
        <p>Firstly, the matrix $\Sigma$ can be taken to be symmetric, without loss of generality, because any antisymmetric component would disappear from the exponent.</p>

        <ul>
          <li>
            <p>Suppose an arbitrary percision matrix $\Lambda$ can be written as $\Lambda^S + \Lambda^A$, where they statify:</p>

\[\begin{aligned} \Lambda^S = \frac {\Lambda_{ij}+\Lambda_{ji}}{2}, \qquad \Lambda^A = \frac {\Lambda_{ij}-\Lambda_{ji}}{2} \end{aligned}\]

            <ul>
              <li>Then $\Lambda^S = (\Lambda^S)^T$, $\Lambda^A = -(\Lambda^A)^T$</li>
              <li>So in the quadratic form, the value of $(\boldsymbol{x} - \boldsymbol{\mu})^T\Lambda^A(\boldsymbol{x} - \boldsymbol{\mu})$ is zero, and then only the symmetric matrix $\Lambda^S$ left.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>Then because $\Sigma$ is rela, symmetric matrix, its eigenvalues will be real, and its eigenvectors can be chosen to form an orthonormal set, so that:</p>

\[\begin{aligned} \boldsymbol{u}_i^T\boldsymbol{u}_j = \left\{\begin{aligned}1\qquad &amp;i=j \\ 0 \qquad &amp;i\neq j \end{aligned} \right. \end{aligned}\]
      </li>
      <li>
        <p>And then, we have:</p>

\[\begin{aligned} \Sigma &amp;= \sum_{i=1}^D \lambda_i \boldsymbol{u}_i\boldsymbol{u}_i^T \\ \Sigma^{-1} &amp;= \sum_{i=1}^D \frac 1 \lambda_i \boldsymbol{u}_i\boldsymbol{u}_i^T \\ \vert \Sigma \vert &amp;= \prod_{i=1}^D \lambda_i  \end{aligned}\]
      </li>
      <li>
        <p>Substituting this reuslt into the quadratic form, we obtain:</p>

\[\begin{aligned} \Delta^2 &amp;= (\boldsymbol{x} - \boldsymbol{\mu})^T \left(\sum_{i=1}^D \frac 1 \lambda_i \boldsymbol{u}_i\boldsymbol{u}_j^T \right)(\boldsymbol{x} - \boldsymbol{\mu}) \\&amp;= \sum_{i=1}^D \frac {y_i^2} {\lambda_i} \qquad let \space y_i = \boldsymbol{u}^T(\boldsymbol{x} - \boldsymbol{\mu}) \end{aligned}\]
      </li>
      <li>Interpreting ${y_i}$ as a new corrdinate system defined by the otthonormal vectors $\boldsymbol{u}_i$ that are shifted and rotated with respect to the original $x_i$ coordinates.
        <ul>
          <li>
            <p>Forming the vector $\boldsymbol{y}=(y_1,y_2,\cdots,y_D)^T$, we have</p>

\[\boldsymbol{y} = U(\boldsymbol{x} - \boldsymbol{\mu})\]

            <ul>
              <li>where the row of $U$ is $\boldsymbol{u}_i^T$, moreover $U$ is an orthogonal matrix, $UU^T = U^TU=I$</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>For the Gaussian distribution to be well defined, it is necessary for all of the eigenvalues $\lambda_i$ of the covariance matrix to be strictly positive, oterwise the distribution cannot be properly normalized.</p>
      </li>
      <li>In going from $\boldsymbol{x}$ to the $\boldsymbol{y}$ corrdinate system, we have a Jacobian matrix $\boldsymbol{J}$, and :</li>
    </ul>

\[\begin{aligned} \frac {\partial y_i}{\partial x_j} = mu_ij = U_{ij} = J_{ij} \end{aligned}\]

    <ul>
      <li>
        <p>Then we can see $\boldsymbol{J} = U$, and $\vert J \vert = \vert U \vert = 1$</p>

\[\begin{aligned} p(\boldsymbol{y}) = p(\boldsymbol{x})\vert J \vert &amp;= \frac {1}{(2\pi)^{D/2}}  \frac {1}{\prod_{i=1}^D \lambda_i^{1/2}} \exp(-\frac 12 \sum_{i=1}^D\frac {y_i^2}{\lambda_i}) \\&amp;= \prod_{i=1}^D \frac 1{(2\pi\lambda_i)^{1/2}} \exp(-\frac {y_i^2}{2\lambda_i}) \end{aligned}\]

        <ul>
          <li>this is the product of $D$ independent univariate Gaussian distribution.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>The Moments of Gaussian distribution</p>

    <ul>
      <li>
        <p>First Order Moments</p>

\[\begin{aligned} \mathbb{E}[\boldsymbol{x}] &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 (\boldsymbol{x} - \boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \right)\boldsymbol{x} d\boldsymbol{x} \\ &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)(\boldsymbol{z}+\boldsymbol{\mu}) d\boldsymbol{z} \end{aligned}\]

        <ul>
          <li>and because $f(\boldsymbol{z}) = \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)\boldsymbol{z}$ is an odd function, then the integrals over the range $(-\infty, \infty)$ will be zero. Thus:</li>
        </ul>

\[\begin{aligned}  \mathbb{E}[\boldsymbol{x}] = \boldsymbol{\mu} \end{aligned}\]
      </li>
      <li>
        <p>Second Order Moments</p>

\[\begin{aligned} \mathbb{E}[\boldsymbol{x}\boldsymbol{x}^T] &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 (\boldsymbol{x} - \boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \right)\boldsymbol{x}\boldsymbol{x}^T d\boldsymbol{x} \\ &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)(\boldsymbol{z}+\boldsymbol{\mu})(\boldsymbol{z}+\boldsymbol{\mu})^T d\boldsymbol{z} \\ &amp;= \boldsymbol{\mu}\boldsymbol{\mu}^T + \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)\boldsymbol{z}\boldsymbol{z}^T d\boldsymbol{z} \end{aligned}\]

        <ul>
          <li>
            <p>and because $\boldsymbol{z} = (\boldsymbol{x}-\boldsymbol{\mu}) = U\boldsymbol{y} = \sum_{j=1}^D y_j \boldsymbol{u}_j$. Thus:</p>

\[\begin{aligned} \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \boldsymbol{z}^T\Sigma^{-1}\boldsymbol{z} \right)\boldsymbol{z}\boldsymbol{z}^T d\boldsymbol{z} &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \int \exp\left(-\frac 12 \sum_{j=1}^D y_j \boldsymbol{u}_j^T \left( \sum_{i=1}^D\frac {1}{\lambda_i}\boldsymbol{u}_i\boldsymbol{u}_i^T \right)\sum_{k=1}^D y_k \boldsymbol{u}_k \right)\sum_{m=1}^D y_m \boldsymbol{u}_m \sum_{n=1}^D y_n \boldsymbol{u}_n^T d\boldsymbol{y} \\ &amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T\int \exp\left(-\frac 12 \left( \sum_{i=1}^D\frac {y_i}{\lambda_i} \boldsymbol{u}_i^T \right)\sum_{k=1}^D y_k \boldsymbol{u}_k \right) y_m y_n d\boldsymbol{y} \\&amp;= \frac {1}{(2\pi)^{D/2}} \frac {1}{\vert\Sigma\vert^{1/2}} \sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T\int \exp\left(-\frac 12 \sum_{i=1}^D\frac {y_i^2}{\lambda_i} \right) y_m y_n d\boldsymbol{y} \\ &amp;= \sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T \prod_{i=1}^D \int \frac {1}{(2\pi \lambda_i)^{1/2}}\exp(-\frac {y_i^2}{2\lambda_i})y_my_n d\boldsymbol{y}\end{aligned}\]

            <ul>
              <li>
                <p>The integrals $\forall i\neq m$, and $i\neq n$ will be 1,so:</p>

\[\begin{aligned} &amp; \left\{\begin{aligned} &amp;\sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T \int \frac {1}{(2\pi \lambda_m)^{1/2}}\exp(-\frac {y_m^2}{2\lambda_m})y_m dy_m y_ndy_n \qquad m\neq n, i = m \\ &amp;\sum_{m=1}^D\sum_{n=1}^D \boldsymbol{u}_m\boldsymbol{u}_n^T \int \frac {1}{(2\pi \lambda_n)^{1/2}}\exp(-\frac {y_n^2}{2\lambda_n})y_ndy_n y_m dy_m \qquad m\neq n, i=n \\ &amp;\sum_{i=1}^D \boldsymbol{u}_i\boldsymbol{u}_i^T \int \frac {1}{(2\pi \lambda_i)^{1/2}}\exp(-\frac {y_i^2}{2\lambda_i})y_i^2 dy_i \qquad i=m=n \end{aligned}\right. \\ =&amp; \left\{\begin{aligned} &amp;0 \qquad m\neq n, i = m \\ &amp;0 \qquad m\neq n, i = n \\ &amp;\sum_{i=1}^D \boldsymbol{u}_i\boldsymbol{u}_i^T (0+\lambda_i) \qquad i=m=n \end{aligned}\right. \end{aligned}\]
              </li>
              <li>
                <p>The final step, we have use the $\mathbb{E}[x^2] = \mu^2 + \sigma^2$, thus:</p>

\[\begin{aligned} \mathbb{E}[\boldsymbol{x}\boldsymbol{x}^T] &amp;= \boldsymbol{\mu}\boldsymbol{\mu}^T + 0 + 0 + \sum_{i=1}^D \boldsymbol{u}_i\boldsymbol{u}_i^T \lambda_i \\ &amp;= \boldsymbol{\mu}\boldsymbol{\mu}^T+ \Sigma\end{aligned}\]
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>And then :</p>

\[\begin{aligned} \mathrm{cov}[\boldsymbol{x}] = \mathbb{E}[\boldsymbol{x}\boldsymbol{x}^T] - \mathbb{E}[\boldsymbol{x}]\mathbb{E}[\boldsymbol{x}]^T = \Sigma \end{aligned}\]
      </li>
    </ul>
  </li>
  <li>
    <p>The number of free parameters in the Gaussian distribution:</p>
    <ul>
      <li>
        <p>A general symmetric covariance matrix $\Sigma$ will have $\frac {D^2-D}{2} + D = \frac {D(D+1)}{2}$ independent parameters, and there  another $D$ independent parameters in $\boldsymbol{\mu}$, then giving $\frac {D(D+3)}{2}$ parameters in total. Thus we can see, it is grows quadratically with $D$</p>
      </li>
      <li>
        <p>If the covariance matrix $\Sigma$ is diagonal, then the number of parameters will be $2D$ in total.</p>
      </li>
      <li>
        <p>Especially, if we consider the covariance matrix $\Sigma$ with $\Sigma = \sigma^2 I$, isotropic covariance, then the number of parameters will be $D+1$ in total.</p>
      </li>
    </ul>
  </li>
</ul>


</div>

<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  
  <div class="post-meta mb-3">
    <i class="far fa-folder-open fa-fw mr-1"></i>
    
      <a href='/categories/probability/'>Probability</a>,
      <a href='/categories/distribution/'>Distribution</a>
  </div>
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw mr-1"></i>
      
      <a href="/tags/gaussian-distribution/"
          class="post-tag no-text-decoration" >Gaussian Distribution</a>
      
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.

      
    </div>

    <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=Gaussian Distribution (1) - Candy Note&amp;url=http://0.0.0.0:4000/posts/gaussian_distribution_1/" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=Gaussian Distribution (1) - Candy Note&amp;u=http://0.0.0.0:4000/posts/gaussian_distribution_1/" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://t.me/share/url?url=http://0.0.0.0:4000/posts/gaussian_distribution_1/&amp;text=Gaussian Distribution (1) - Candy Note" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    

    <i id="copy-link" class="fa-fw fas fa-link small"
        data-toggle="tooltip" data-placement="top"
        title="Copy link"
        data-title-succeed="Link copied successfully!">
    </i>

  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


      
    
    

    </div>
  </div> <!-- #core-wrapper -->

  <!-- pannel -->
  <div id="panel-wrapper" class="col-xl-3 pl-2 text-muted">

    <div class="access">
      















      















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">Trending Tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/gaussian-distribution/">Gaussian Distribution</a>
    
      
      <a class="post-tag" href="/tags/pca/">PCA</a>
    
      
      <a class="post-tag" href="/tags/em/">EM</a>
    
      
      <a class="post-tag" href="/tags/bayesian/">Bayesian</a>
    
      
      <a class="post-tag" href="/tags/markov-chain/">Markov Chain</a>
    
      
      <a class="post-tag" href="/tags/bernoulli/">Bernoulli</a>
    
      
      <a class="post-tag" href="/tags/binomial/">Binomial</a>
    
      
      <a class="post-tag" href="/tags/gamma-distribution/">Gamma Distribution</a>
    
      
      <a class="post-tag" href="/tags/gmm/">GMM</a>
    
      
      <a class="post-tag" href="/tags/kernel/">Kernel</a>
    

    </div>
  </div>


    </div>

    
      
      



<!-- BS-toc.js will be loaded at medium priority -->
<script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script>

<div id="toc-wrapper" class="pl-0 pr-4 mb-5">
  <div class="panel-heading pl-3 pt-2 mb-2">Contents</div>
  <nav id="toc" data-toggle="toc"></nav>
</div>


    
  </div>

</div>

<!-- tail -->

<div class="row">
  <div class="col-12 col-lg-11 col-xl-8">
    <div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">
      
        
        <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  
    
  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  








<!-- Fill with the other newlest posts  -->






  <div id="related-posts" class="mt-5 mb-2 mb-sm-4">
    <h3 class="pt-2 mt-1 mb-4 ml-1"
      data-toc-skip>Further Reading</h3>
    <div class="card-deck mb-4">
    
      
      
      <div class="card">
        <a href="/posts/gaussian_distribution_2/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/timeago.js
-->

<em class="timeago small"
    data-ts="1613779200"
    
    >
  2021-02-20
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Gaussian Distribution (2)</h3>
            <div class="text-muted small">
              <p>
                





                Maximum Likelihood for the Gaussian


  
    Given a data set $\mathbf{X} = {\mathbf{x}_1,\mathbf{x}_2,\cdots, \mathbf{x}_N}$ which are drawn independently from a multivariate Gaussian distribution...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/gaussian_distribution_3/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/timeago.js
-->

<em class="timeago small"
    data-ts="1613779200"
    
    >
  2021-02-20
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Gaussian Distribution (3)</h3>
            <div class="text-muted small">
              <p>
                





                Conditional Gaussian Distribution


  
    we partition $\boldsymbol{x}$ into disjoint subsets $\boldsymbol{x}_a, \boldsymbol{x}_b$

    \(\begin{aligned} \boldsymbol{x} &amp;amp;= \binom{\boldsymbol{x...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/gaussian_gamma_distribution/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/timeago.js
-->

<em class="timeago small"
    data-ts="1613779200"
    
    >
  2021-02-20
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Gaussian-Gamma Distribution</h3>
            <div class="text-muted small">
              <p>
                





                Gaussian-Gamma distribution

\[\begin{aligned} \mathrm{GausGam}(\mu, \lambda  \vert \mu_0, \tau , a, b) &amp;amp;= \mathcal{N}(\mu \vert \mu_0, (\tau\lambda)^{-1}) \mathrm{Gam}(\lambda \vert a,b)  \\ &amp;...
              </p>
            </div>
          </div>
        </a>
      </div>
    
    </div> <!-- .card-deck -->
  </div> <!-- #related-posts -->


      
        
        <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <a href="/posts/gamma_distribution/" class="btn btn-outline-primary"
    prompt="Older">
    <p>Gamma Distribution</p>
  </a>
  

  
  <a href="/posts/gaussian_distribution_2/" class="btn btn-outline-primary"
    prompt="Newer">
    <p>Gaussian Distribution (2)</p>
  </a>
  

</div>

      
        
        <!--  The comments switcher -->


      
    </div>
  </div>
</div> <!-- .row -->



        <!--
  The Footer
-->

<footer class="d-flex w-100 justify-content-center">
  <div class="d-flex justify-content-between align-items-center text-muted">
    <div class="footer-left">
      <p class="mb-0">
        © 2022
        <a href="https://twitter.com/username">luo-songtao</a>.
        
        <span data-toggle="tooltip" data-placement="top"
          title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
        
      </p>
    </div>

    <div class="footer-right">
      <p class="mb-0">
        

        

        Powered by 
          <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>
         with 
          <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>
         theme.

      </p>
    </div>

  </div> <!-- div.d-flex -->
</footer>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-sm-11 post-content">
    <div id="search-hints">
      















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">Trending Tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/gaussian-distribution/">Gaussian Distribution</a>
    
      
      <a class="post-tag" href="/tags/pca/">PCA</a>
    
      
      <a class="post-tag" href="/tags/em/">EM</a>
    
      
      <a class="post-tag" href="/tags/bayesian/">Bayesian</a>
    
      
      <a class="post-tag" href="/tags/markov-chain/">Markov Chain</a>
    
      
      <a class="post-tag" href="/tags/bernoulli/">Bernoulli</a>
    
      
      <a class="post-tag" href="/tags/binomial/">Binomial</a>
    
      
      <a class="post-tag" href="/tags/gamma-distribution/">Gamma Distribution</a>
    
      
      <a class="post-tag" href="/tags/gmm/">GMM</a>
    
      
      <a class="post-tag" href="/tags/kernel/">Kernel</a>
    

    </div>
  </div>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    
      <!--
  mermaid-js loader
-->

<script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script>

<script>
  $(function() {
    function updateMermaid(event) {
      if (event.source === window && event.data &&
            event.data.direction === ModeToggle.ID) {

        const mode = event.data.message;

        if (typeof mermaid === "undefined") {
          return;
        }

        let expectedTheme = (mode === ModeToggle.DARK_MODE? "dark" : "default");
        let config = { theme: expectedTheme };

        /* Re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */
        $(".mermaid").each(function() {
          let svgCode = $(this).prev().children().html();
          $(this).removeAttr("data-processed");
          $(this).html(svgCode);
        });

        mermaid.initialize(config);
        mermaid.init(undefined, ".mermaid");
      }
    }

    let initTheme = "default";

    if ($("html[data-mode=dark]").length > 0
      || ($("html[data-mode]").length == 0
        && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) {
      initTheme = "dark";
    }

    let mermaidConf = {
      theme: initTheme  /* <default|dark|forest|neutral> */
    };

    /* Markdown converts to HTML */
    $("pre").has("code.language-mermaid").each(function() {
      let svgCode = $(this).children().html();
      $(this).addClass("unloaded");
      $(this).after(`<div class=\"mermaid\">${svgCode}</div>`);
    });

    mermaid.initialize(mermaidConf);

    window.addEventListener("message", updateMermaid);
  });
</script>

    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No result founds.</p>',
  templateMiddleware: function(prop, value, template) {
    if (prop === 'categories') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
      }
    }

    if (prop === 'tags') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
      }
    }
  }
});
</script>


    <!--
  JS selector for site.
-->

<!-- layout specified -->


  



  <!-- image lazy-loading & popup & clipboard -->
  

  







  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script>







  

  

  







  
    

    

  



  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script>








<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
  /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
  MathJax = {
    tex: {
      inlineMath: [              /* start/end delimiter pairs for in-line math */
        ['$','$'],
        ['\\(','\\)']
      ],
      displayMath: [             /* start/end delimiter pairs for display math */
        ['$$', '$$'],
        ['\\[', '\\]']
      ]
    }
  };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>


<!-- commons -->

<script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script>




  </body>

</html>

