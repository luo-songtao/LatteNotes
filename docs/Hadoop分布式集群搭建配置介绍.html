<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <meta name="generator" content="Jekyll">

  <title>Hadoop分布式集群搭建配置介绍</title>
  <link rel="stylesheet" href="/notes/css/main.css">

  <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="ATOM Feed" /> <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Hadoop分布式集群搭建配置介绍 | LuoSongtao-Blog</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Hadoop分布式集群搭建配置介绍" />
<meta name="author" content="LuoSongtao" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="环境准备" />
<meta property="og:description" content="环境准备" />
<link rel="canonical" href="http://0.0.0.0:4000/notes/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D" />
<meta property="og:url" content="http://0.0.0.0:4000/notes/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D" />
<meta property="og:site_name" content="LuoSongtao-Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-25T00:00:00-06:00" />
<script type="application/ld+json">
{"datePublished":"2019-01-25T00:00:00-06:00","dateModified":"2019-01-25T00:00:00-06:00","author":{"@type":"Person","name":"LuoSongtao"},"description":"环境准备","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/notes/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D"},"@type":"BlogPosting","url":"http://0.0.0.0:4000/notes/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D","headline":"Hadoop分布式集群搭建配置介绍","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>

<body>
  <div id="wrapper">
    <header>
  <div style="text-align: center;">
    <div>
      <a id="username" href="/notes/">
      
      <span style="font-size: x-large;color: #b5e853">luosongtao@home:~$</span>
      </a>
      
<div id="search">
	<input type="text" id="search-input" placeholder="Command.." style="vertical-align:middle;">
	<ul id="results-container"></ul>
</div>

<!-- script pointing to jekyll-search.js -->
<script src="/notes/assets/js/simple-jekyll-search.min.js"></script>
<script async src="/notes/searchdata.js"></script>

    </div>
  </div>
  <div class="header-links">
      <a href="/notes/archive"><h2 class="header-link">Archive</h2></a>
<a href="/notes/about"><h2 class="header-link">About</h2></a>
<a href="/notes/atom.xml"><h2 class="header-link">RSS</h2></a>
  </div>

</header>
    <div class="container">
        <article>
  <h2>Hadoop分布式集群搭建配置介绍</h2>
  <time datetime="2019-01-25T00:00:00-06:00" class="by-line">25 Jan 2019</time>
  <h4 id="环境准备">环境准备</h4>

<ol>
  <li>
    <p>软件版本示例</p>

    <p>系统：CentOS7.5为例、2C4G</p>

    <p>三台服务器分配的IP地址：192.168.19.137/138/139</p>

    <p>规划：137作为hadoop-master，其他两台作为数据节点138、139分别为hadoop-slave1、hadoop-slave2</p>

    <p>jdk使用1.8版本</p>

    <p>hadoop使用2.9.1版本，下载地址：http://apache.claz.org/hadoop/common/hadoop-2.9.1/hadoop-2.9.1.tar.gz</p>
  </li>
  <li>
    <p>host配置和主机名配置</p>

    <p>修改所有服务器的<code class="highlighter-rouge">/etc/hosts</code>文件，添加以下配置</p>
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 192.168.19.137 hadoop-master
 192.168.19.138 hadoop-slave1
 192.168.19.139 hadoop-slave2
</code></pre></div>    </div>
    <p>依次修改所有的服务器的主机名：HOSTNAME，以hadoop-master为例：在137服务器上</p>

    <p><code class="highlighter-rouge">vi /etc/susconfig/network</code></p>
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> HOSTNAME=hadoop-master
</code></pre></div>    </div>

    <p>执行<code class="highlighter-rouge">reboot now</code>后生效，注意需要一次修改每一台服务，改为对应的hadoop-slave1、hadoop-slave2等</p>

    <p>之后的配置将使用HOSTNAME进行域名配置，这样便于管理和识别</p>
  </li>
  <li>
    <p>JDK安装：
 方法一：官网下载JDK，https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
 方法二：使用安装JDK：`yum -y install java-1.8.0-openjdk*</p>

    <p>安装后，配置环境变量，这里以方法一为例：</p>

    <p>下载JDK1.8.0解压放到<code class="highlighter-rouge">/root/bigdata</code>目录下，并设置软连接<code class="highlighter-rouge">/root/bigdata/jdk</code>指向它
 <code class="highlighter-rouge">vi /root/.bash_profile</code></p>
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> export JAVE_HOME=/root/bigdata/jdk
 export PATH=$PATH:$JAVA_HOME/bin
</code></pre></div>    </div>

    <p>使用<code class="highlighter-rouge">source /root/.bash_profile</code>是配置立即生效</p>
  </li>
</ol>

<h4 id="免密登录">免密登录</h4>

<ol>
  <li>
    <p>以下以hadoop-master为例，配置服务器的本机无密码登录：</p>

    <p>生成密钥：<code class="highlighter-rouge">ssh-keygen -t rsa</code></p>

    <p>追加公钥：<code class="highlighter-rouge">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</code></p>

    <p>设置权限：<code class="highlighter-rouge">chmod 600 ~/.ssh/authorized_keys</code></p>

    <p>验证本机能否无密码登录：<code class="highlighter-rouge">ssh hadoop-master</code></p>

    <p>其余机器同样的步骤设置</p>
  </li>
  <li>
    <p>以下设置hadoop-master无密码登录hadoop-slave1、hadoop-slave2</p>

    <p>在hadoop-slave1上：</p>
    <ul>
      <li>
        <p>先复制hadoop-master上的公钥到hadoop-slave1的<code class="highlighter-rouge">/root</code>目录下：
 <code class="highlighter-rouge">scp root@hadoop-master:/root/.ssh/id_rsa.pub /root/</code></p>
      </li>
      <li>
        <p>然后将hadoop-master的公钥追加到hadoop-slave1的authorized_keys中：</p>
        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> cat /root/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys
 rm -rf /root/id_rsa.pub
</code></pre></div>        </div>
      </li>
    </ul>

    <p>在hadoop-master测试无密码登录hadoop-slave1：<code class="highlighter-rouge">ssh hadoop-slave1</code></p>

    <p>hadoop-slave2同理依次配置</p>
  </li>
  <li>
    <p>与2相反，hadoop-slave1、hadoop-slave2也需要设置无密码登录hadoop-master，设置方法同理</p>
  </li>
</ol>

<h4 id="hadoop-master的安装与配置">hadoop-master的安装与配置</h4>

<p>配置hadoop-master的hadoop环境</p>
<ol>
  <li>
    <p>hadoop-master上下载并解压hadoop安装包放到指定目录，如<code class="highlighter-rouge">/root/bigdata/</code>，并未其设置软连接<code class="highlighter-rouge">/root/bigdata/hadoop</code></p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> wget http://apache.claz.org/hadoop/common/hadoop-2.9.1/hadoop-2.9.1.tar.gz
 tar -xvf hadoop-2.9.1.tar.gz
 mv hadoop-2.9.1 /root/bigdata/
 ln -s /root/bigdata/hadoop-2.9.1 /root/bigdata/hadoop
</code></pre></div>    </div>
  </li>
  <li>
    <p>配置hadoop-master的hadoop环境变量：</p>

    <p>编辑<code class="highlighter-rouge">vi /root/.bash_profile</code></p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> export HADOOP_HOME=/root/bigdata/hadoop
 export PATH=$PATH:$HADOOP_HOME/bin
</code></pre></div>    </div>

    <p>使用<code class="highlighter-rouge">source /root/.bash_profile</code>使之生效</p>
  </li>
</ol>

<p><strong>注意：进入<code class="highlighter-rouge">/root/bigdata/hadoop/etc/hadoop</code>目录</strong></p>

<ol>
  <li>
    <p>配置core-site.xml，修改hadoop的核心配置文件</p>

    <p><code class="highlighter-rouge">hadoop.tmp.dir</code>：指定hadoop数据存储的临时文件夹；</p>

    <p><code class="highlighter-rouge">fs.default.name</code>：指定NameNonde的IP地址和端口号</p>
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> &lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
         &lt;value&gt;/root/bigdata/hadoop/tmp&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
         &lt;name&gt;fs.defaultFS&lt;/name&gt;
         &lt;value&gt;hdfs://hadoop-master:9000&lt;/value&gt;
     &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre></div>    </div>
    <p><strong>注意：如没有配置<code class="highlighter-rouge">hadoop.tmp.dir</code>参数，此时系统默认的临时目录为：<code class="highlighter-rouge">/tmp</code>。而这个目录在每次重启后都会可能被删除，届时必须重新执行format才行，否则会出错</strong></p>

    <p>因此这里指定为hadoop home目录下的tmp路径。为避免带来其他问题，建议手动创建并赋予权限<code class="highlighter-rouge">mkdir /root/bigdata/hadoop/tmp &amp;&amp; chmod 777 /root/bigdata/hadoop/tmp</code></p>
  </li>
  <li>
    <p>配置hdfs-site.xml，修改HDFS的核心配置文件</p>

    <p><code class="highlighter-rouge">dfs.replication</code>：指定HDFS的备份因子</p>

    <p><code class="highlighter-rouge">dfs.name.dir</code>：指定namenode节点的文件存储目录</p>

    <p><code class="highlighter-rouge">dfs.data.dir</code>：指定datanode节点的文件存储目录</p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  &lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.replication&lt;/name&gt;
         &lt;value&gt;3&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.name.dir&lt;/name&gt;
         &lt;value&gt;/root/bigdata/hadoop/hdfs/name&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.data.dir&lt;/name&gt;
         &lt;value&gt;/root/bigdata/hadoop/hdfs/data&lt;/value&gt;
     &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre></div>    </div>
  </li>
  <li>
    <p>配置mapred-site.xml，修改MapReduce的核心配置文件</p>

    <p>先拷贝mapred-site.xml.template为mapred-site.xml，再进行修改</p>

    <p><code class="highlighter-rouge">mapreduce.framework.name</code>：设定yarn为MapReduce的资源管理器</p>

    <p><code class="highlighter-rouge">mapred.job.tracker</code>：配置HTTP地址与端口</p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> &lt;configuration&gt;
   &lt;property&gt;
       &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
       &lt;value&gt;yarn&lt;/value&gt;
   &lt;/property&gt;
    &lt;property&gt;
       &lt;name&gt;mapred.job.tracker&lt;/name&gt;
       &lt;value&gt;http://hadoop-master:9001&lt;/value&gt;
   &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre></div>    </div>
  </li>
  <li>
    <p>配置yarn-site.xml</p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> &lt;configuration&gt;
 &lt;!-- Site specific YARN configuration properties --&gt;
     &lt;property&gt;
         &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
         &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
         &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
         &lt;value&gt;hadoop-master&lt;/value&gt;
     &lt;/property&gt;

 &lt;/configuration&gt;
</code></pre></div>    </div>
  </li>
  <li>
    <p>配置masters文件</p>

    <p>编辑<code class="highlighter-rouge">vi /root/bigdata/hadoop/etc/hadoop/masters</code>，如果没有则新建，该文件指定namenode节点所在的服务器</p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hadoop-master
</code></pre></div>    </div>
  </li>
  <li>
    <p>配置slaves文件：(该文件只在Master机器上配置)</p>

    <p>编辑<code class="highlighter-rouge">vi /root/bigdata/hadoop/etc/hadoop/slaves</code>，该文件指定哪些服务器节点是datanode节点。删除locahost，添加所有datanode节点的主机名，即slave节点</p>
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> hadoop-slave1
 hadoop-slave2
</code></pre></div>    </div>
    <h4 id="hadoop-slave的安装与配置">hadoop-slave的安装与配置</h4>
  </li>
</ol>

<p>hadoop slave服务器的配置与master的配置全部同步，以master为主，因此配置方法如下：</p>

<ol>
  <li>拷贝master服务器上的hadoop目录到slave机器上，如在master服务器上：
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> scp -r /root/bigdata/hadoop hadoop-slave1:/root/bigdata/
 scp -r /root/bigdata/hadoop hadoop-slave2:/root/bigdata/
 # 有多个则一一拷贝
</code></pre></div>    </div>
  </li>
  <li>
    <p>分别将slave机器上的hadoop配置文件夹(<code class="highlighter-rouge">hadoop/etc/hadoop</code>)里的slaves文件删除，该文件是master服务器独有的</p>
  </li>
  <li>在slave机器上配置hadoop的环境变量<code class="highlighter-rouge">vi /root/.bash_profile</code>：
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>export HADOOP_HOME=/root/bigdata
export PATH=$PATH:$HADOOP_HOME/bin
</code></pre></div>    </div>
  </li>
</ol>

<p><code class="highlighter-rouge">source /root/.bash_profile</code></p>

<h4 id="启动hadoop集群">启动Hadoop集群</h4>

<p>完成以上配置则可以开始启动Hadoop集群</p>

<p>但在启动前还需要设置防火墙，测试阶段可以直接关闭所有机器的防火墙<code class="highlighter-rouge">service firewalld stop</code>，生成环境那么就需要设置端口过滤规则，这里不赘述</p>

<ol>
  <li>
    <p>初始化HDFS文件系统：</p>

    <p>在master服务器上：<code class="highlighter-rouge">hadoop namenode -format</code></p>

    <p>该命令只需要在第一次启动服务前执行，之后不用再执行</p>
  </li>
  <li>
    <p>启动Hadoop：</p>

    <p>在master服务器上：<code class="highlighter-rouge">/root/bigdata/hadoop/sbin/start-all.sh</code></p>
  </li>
  <li>
    <p>运行成功后，分别在master和slave服务器上使用<code class="highlighter-rouge">jps</code>查看hadoop的运行进程：</p>

    <p>master应有类似如下的几个进程：</p>
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 4673 SecondaryNameNode
 4475 NameNode
 4831 ResourceManager
</code></pre></div>    </div>

    <p>每个slave应有类似如下的几个进程：</p>
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 2405 DataNode
 2521 NodeManager
</code></pre></div>    </div>
  </li>
</ol>

<p>同时也可以通过master服务器的50070端口查看hadoop的WEB界面</p>

</article>
      <section id="main_content">
        <ul>
            
        </ul>
      </section>
    </div>
  </div>
   <footer>
  <a href="/">
    <span>
        <b>LuoSongtao</b>
    </span>
    
    <span>© 2019</span>
  </a>
</footer>

  
</body>

</html>